EmergenceofCompositionalRepresentationsinRestrictedBoltzmannMachinesJ.Tubiana,R.MonassonLaboratoiredePhysiqueTh´eorique,EcoleNormaleSup´erieureandCNRS,PSLResearch,SorbonneUniversit´esUPMC,24rueLhomond,75005Paris,France(Dated:March6,2017)Extractingautomaticallythecomplexsetoffeaturescomposingrealhigh-dimensionaldataiscrucialforachievinghighperformanceinmachine–learningtasks.RestrictedBoltzmannMachines(RBM)areempiricallyknowntobeeﬃcientforthispurpose,andtobeabletogeneratedistributedandgradedrepresentationsofthedata.Wecharacterizethestructuralconditions(sparsityoftheweights,loweﬀectivetemperature,nonlinearitiesintheactivationfunctionsofhiddenunits,andadaptationofﬁeldsmaintainingtheactivityinthevisiblelayer)allowingRBMtooperateinsuchacompositionalphase.EvidenceisprovidedbythereplicaanalysisofanadequatestatisticalensembleofrandomRBMsandbyRBMtrainedonthehandwrittendigitsdatasetMNIST.Recentyearshavewitnessedmajorprogressesinsu-pervisedmachinelearning,e.g.invideo,audio,im-ageprocessing,...[1].Despitethoseimpressivesuc-cesses,unsupervisedlearning,inwhichthestructureofdataislearnedwithoutaprioriknowledgestillpresentsformidablechallenges.Afundamentalquestionishowtolearnprobabilitydistributionsthatﬁtwellcomplexdatamanifoldsinhigh-dimensionalspaces[2].Oncelearnt,suchgenerativemodelscanbeusedfordenoising,comple-tion,artiﬁcialdatageneration,...Hereafterwefocusononeimportantgenerativemodel,RestrictedBoltzmannMachines(RBM)[3,4].InitssimplestformulationaRBMisaBoltzmannmachineonabipartitegraph,seeFig.1(a),withavisible(v)layerthatrepresentsthedata,connectedtoahidden(h)layermeanttoextractandex-plaintheirstatisticalfeatures.Themarginaldistributionoverthevisiblelayerisﬁttedtothedatathroughapprox-imatelikelihoodmaximization[5–8].Oncetheparame-tersaretrainedeachhiddenunitbecomesselectivelyac-tivatedbyaspeciﬁcdatafeature;owetothebidirection-alityofconnectionstheprobabilitytogenerateconﬁgu-rationsofthevisiblelayerwherethisfeatureispresentis,inturn,increased.Multiplecombinationsofnumbersoffeatures,withvaryingdegreesofactivationofthecor-respondinghiddenunitsallowforeﬃcientgenerationofalargevarietyofnewdatasamples.However,theexis-tenceofsuch‘compositional’encodingseemstodependonthevaluesoftheRBMparameters,suchasthesizeofthehiddenlayer[9].CharacterizingtheconditionsunderwhichRBMcanoperateinthiscompositionalregimeisthepurposeofthepresentwork.IntheRBMshowninFig.1(a)thevisiblelayerin-cludesNunitsvi,withi=1,...,N,chosenheretobebinary(=0,1).VisibleunitsareconnectedtoMhiddenunitshµ,throughtheweights{wiµ}.Theenergyofaconﬁgurationv={vi},h={hµ}isdeﬁnedthroughE[v,h]=−NXi=1MXµ=1wiµvihµ−NXi=1givi+MXµ=1Uµ(hµ),(1)whereUµisapotentialactingonhiddenunitµ;dueFIG.1:(a)ArchitectureofRBM.Visible(vi,i=1,...,N)andhidden(hµ,µ=1,..,M)unitsareconnectedthroughweights(wiµ).(b)ActivationfunctionsΦofBernoulli,Lin-earandRectiﬁedLinearUnits.ThecorrespondingpotentialsareULin(h)=h22;UBer(h)=hθBifh=0or1,and+∞otherwise;UReLU(h)=h22+hθforh≥0,+∞forh<0.(c)Thethreeregimesofoperation,seetext.Black,greyandwhitehiddenunitssymbolize,respectively,strong,weakandnullactivations.tothebinarynatureofthevisibleunitstheirpotentialisfullycharacterizedbyalocalﬁeld,giin(1).Con-ﬁgurationsarethensampledfromtheGibbsequilibriumdistributionassociatedtoE,P[v,h]=exp(−E[v,h])/Z,whereZisthepartitionfunction[3].GivenavisibleconﬁgurationvthemostlikelyvaluehµofhiddenunityµisafunctionofitsinputIµ=PNi=1wiµvi:hµ=Φµ(Iµ),wheretheactivationfunctionΦµ=(U0µ)−1ascanbeseenfromtheminimizationofE.ExamplesofΦareshowninFig.1(b).WhenΦislinear,i.e.forquadraticpotentialUtheprobabilityP[v,h]isGaussianinthehiddenunits,andthemarginaldistribu-tionP[v]ofthevisibleconﬁgurationsvcanbeexactlycomputed[10].Itcoincideswiththeequilibriumdistribu-tionofaBoltzmannmachinewithapairwiseinteractionmatrixJij=Pµwiµwjµ,or,equivalently,ofaHopﬁeldmodel[11],whoseMpatternswµarethecolumnsoftheweightmatrix{wiµ}.ActivationfunctionsΦempiricallyknowninmachine–arXiv:1611.06759v2  [physics.data-an]  2 Mar 20172learningliteraturetoprovidegoodresultsare,however,nonlinear.NonlinearΦproduceeﬀectiveBoltzmannma-chineswithhighorder(>2)multibodyinteractionsbe-tweenthevisibleunitsvi.TwoexamplesareshowninFig.1(b):Bernoulliunits,whichtakediscrete0,1values,andRectiﬁedLinearUnits(ReLU)[1].UnlikeBernoulliunitsReLUpreserveinformationaboutthemagnitudesoftheirinputsabovethreshold[12];thispropertyisex-pectedforrealneuronsandReLUwereﬁrstintroducedinthecontextoftheoreticalneuroscience[13].WeﬁrstreportresultsfromatrainingexperimentofRBMwithReLUonthehandwrittendigitsdatasetMNIST[14].Ourgoalisnottoclassifydigitsfrom0to9,buttolearnagenerativemodelofdigitsfromex-amples.DetailsaboutlearningcanbefoundinSup-plementalMaterial,SectionI.Figure2(a)showstypi-cal‘features’wµ={wiµ}afterlearning.Eachfeatureincludesnegativeandpositiveweights,andislocalizedaroundsmallportionsofthevisiblelayer.Thesefea-tureslooklikeelementarystrokes,whicharecombinedbytheRBMtogeneraterandomdigits(Fig.2(b)).IneachgeneratedhandwrittendigitimageˆS’240hiddenunitsaresilent(hµ=0),seehistograminFig.2(c).Theremaininghiddenunitshavelargelyvaryingactivations,someweakandfewverystrong;weestimatethenum-berofstronglyactivatedonesthroughtheparticipationratioˆL=[(Pµhaµ)2/Pµh2aµ],withexponenta=3asexplainedbelow.OnaverageˆL’20elementarystrokescomposeagenerateddigit,seeFig.2(c).Diﬀerentcombi-nationsofstrokescorrespondtodiﬀerentvariantsofthesamedigits.Manyofthosevariantsarenotcontainedinthetrainingset,andcloselymatchdigitsinthetestset(SupplementalMaterial,Fig.1(b)),henceshowingthegenerativepowerofRBM.LearningisaccompaniedbystructuralchangesinRBM,whichwetrackwithtwoparameters:ˆp=1MNPµ[(Piw2iµ)2/Piw4iµ]andW2=1MPi,µw2iµ.Thoseparametersareproxiesfor,respectively,thefrac-tionofnonzeroweightsandtheeﬀectiveinversetempera-ture,seeSupplementalMaterial,SectionIII.Figure2(d)showsthatˆpdiminishestosmallvalues∼0.1,whereasW2increases.Whilemostweightsbecomeverysmallandnegligibletheremainingonesgetlarge,inagreementwithFig.2(a).Noticethatsparsityisnotimposedtoobtainaspeciﬁcclassoffeatures,e.g.asin[15],butnaturallyemergesthroughlikelihoodmaximizationacrosstrain-ing.Thepresenceoflargeweightsimpliesthatﬂippingvisibleunitsisassociatedtolargeenergycosts.Visibleunitsareeﬀectivelyatverylowtemperature,ascanbeseenfromthequasibinarynatureofconditionalaveragesinFig.2(b)andSupplementalMaterial,Fig.5.WearguebelowthatthesestructuralchangesarenotspeciﬁctoMNIST-trainedRBMbutaregenericallyneededtobringRBMtowardsacompositionalphase,inwhichvisibleconﬁgurationsarecomposedfromcombina-FIG.2:TrainingofRBMonMNIST,withN=28×28visibleunitsandM=400hiddenReLU.(a)Setofweightswµat-tachedtofourhiddenunitsµ.(b)Averagesofvconditionedtoﬁvehidden-unitconﬁgurationshsampledfromtheRBMatequilibrium.Blackandwhitepixelscorrespondrespectivelytoaveragesequalto0and1;fewintermediaryvalues,indi-catedbygreylevels,canbeseenontheedgesofdigits.(c)DistributionsofˆL(left)andˆS(right)inhidden-unitconﬁg-urationsatequilibrium.(d)Evolutionoftheweightsparsityˆp(red)andthesquaredweightvalueW2(blue);Thetrainingtimeismeasuredinepochs(numberofpassesoverthedataset),andrepresentedonasquare–rootscale.tionsofalargenumberL(typically,1(cid:28)L(cid:28)M,asinFig.2(c))offeaturesencodedbysimultaneously,stronglyactivatedhiddenunits.Ourclaimissupportedbyade-tailedanalysisofaRandomRBM(R-RBM)ensemble,inwhichtheweightswiµarequenchedrandomvariables,withcontrolledsparsityandstrength,andthemagnitudeofthevisibleﬁeldsandthevaluesoftheReLUthresholdscanbechosen.Foradequatechoicesofthesecontrolpa-rametersthecompositionalphaseisthermodynamicallyfavouredwithrespecttotheferromagneticphaseoftheHopﬁeldmodel,whereonepatternisactivated[16],andtothespin-glassphase,inwhichallhiddenunitsareweaklyandincoherentlyactivated(Fig.1(c)).IntheR-RBMensembleweightswiµareindependentrandomvariables,equalto−1√N,0,+1√Nwithprobabili-tiesequalto,respectively,pi2,1−pi,pi2;pi∈[0;1]setsthedegreeofsparsityoftheweightsattachedtothevisibleunitvi,highsparsitiescorrespondingtosmallpi.Thees-timatorˆpdeﬁnedabove(Fig.2(d))measuresthefractionofnonzeroweights,p=Pipi/N.Thisdistributionwaspreviouslyintroducedtostudyparallelstorageofmul-tiplesparseitemsintheHopﬁeldmodel[17,18].Forsimplicitytheﬁeldsonvisibleunitsandthepotentialsactingonhiddenunitsarechosentobeuniform,gi=gandUµ=UReLU(Fig.1(a)).Wedeﬁnetheratioofthenumbersofhiddenandvisibleunits,α=M/N.Givenavisiblelayerconﬁgurationv,hiddenunitsµcodingforfeatureswµpresentinvwillbestronglyac-3tivated:theirinputsIµ=wµ·vwillbestrongandpositive,comparabletotheproductofthenormsofwµ(’√pforlargeN)andv(oftheorderof√pN),and,hence,willscaleasm√N,wherem,calledmagnetiza-tion,isﬁnite.Mosthiddenunitsµ0have,however,fea-tureswµ0essentiallyorthogonaltov,andreceiveinputsIµ0ﬂuctuatingaround0,withﬁnitevariances.ThesescalingsensurethatˆLdeﬁnedabove(Fig.2(c))willcoin-cidewiththenumberLofstronglyactivatedunitswhenN→∞;choosingexponenta=2inˆLratherthana=3wouldhaveintroducedbiasescomingfromweaklyacti-vatedunits(SupplementalMaterial,SectionIII.B).Thetypicalgroundstate(GS)energyE(1)ofR-RBMcanbecomputedwiththereplicamethodwithinthereplica-symmetricAnsatz[16],astheoptimumofEGS=L2m2+α2(qB+rC)−1NXi√αpir(2)×(cid:28)H(1)(cid:18)−(cid:20)g+α2Bpi+mW(cid:21)/√αpir(cid:19)(cid:29)W+αZDzminh(cid:18)UReLU(h)−C2h2−z√pqh(cid:19)overtheorderparametersm,L,r,q,B,C(averagedoverthequenchedweights):mandLare,respectively,themagnetizationandthenumberoffeature-encodinghid-denunits,risthemeansquaredactivityoftheotherhiddenunits,q=PipihviiGS/(Np)istheweightedac-tivityofthevisiblelayerintheGS,andB,Careresponsefunctions,i.e.derivativesofthemeanactivityof,respec-tively,hiddenandvisibleunitswithrespecttotheirin-puts[20].In(2)Dz=dz√2πe−z2/2denotestheGaussianmeasure,H(k)(x)=RxDz(z−x)k,andh·iWistheav-erageoverthesumWofLi.i.d.weightswiµdrawnasabove.WeﬁrstﬁxL,andoptimizeEGSoveralltheotheror-derparameters.Atlargeαtheonlysolutionhasm=0,andcorrespondstotheSpin-Glassphase.Forintermedi-atevaluesofα,othersolutions,withm>0,exist.Forthesakeofsimplicityweconsiderﬁrstthehomogenoussparsitycase,withpi=p.WeshowinFig.3(a),forﬁxedp=0.1andvariousvaluesofL,themaximalvalueofαbelowwhichaphasewithLmagnetizedhiddenunitsex-ists.Importantlythiscriticalvaluecanbemadearbitrar-ilylargebyincreasingtheReLUthresholdθ.Thisphe-nomenonisaconsequenceofthenonlinearityofReLU,andcanbeunderstoodasfollows.Thesquaredactivityrofnon-magnetizedhiddenunitsobeysthesaddle-pointequationr=pq/(1−C)2×H(2)(θ/√pq).Theﬁrstfactorisreminiscentoftheexpressionr=1/(1−C)2arisingfortheHopﬁeldmodel(forwhichp=q=1atzerotemperature)[16],whilethesecondfactorcomesfromthenonlinearityofReLU.H(2)beingarapidlydecayingfunctionofitsargumentlargethresholdsθleadtosmallrvalues.AsthelevelofcrosstalkduetononmagnetizedhiddenunitsdiminisheslargerratiosαcanbesupportedbyR-RBMwithoutenteringtheglassyphase.NumericalsimulationsofR-RBMsatlargeαconﬁrmtheexistenceand(meta)stabilityofphaseswithLnonzeromagneti-zations(Fig.3(b)).Moreover,thevaluesoftheaveragenormalizedmagnetizations˜m=m/(p/2)∈[0;1]areinexcellentagreementwiththosefoundbyoptimizingEGS.FIG.3:CompositionalregimeinR-RBM.(a)Criticallinesintheθ,αplanebelowwhichLhiddenunitsmaybestronglyactivated,calculatedfromtheoptimizationofEGS(2).Pa-rametersarepi=p=0.1,g=−0.02.(b)Comparisonoftheoretical(redcrosses)andnumericalsimulations(N=104visibleunits,coloredpoints)fortherescaledmagnetizations˜m=m/(p/2))asafunctionofthenumberLofstronglyactivatedhiddenunitsinR-RBM.7,500zerotemperatureMCMC,eachinitializedwithavisibleconﬁgurationstronglyoverlappingwithL=1,2,...‘features’,werelaunched;colorcodeindicatestheprobabilitythatthesameLhiddenunitsaremagnetizedafterconvergence(seebottomscale),andthecorrespondingaveragemagnetization˜m.Thenatureofthelarge–LphasesandtheselectionofthevalueofLarebestunderstoodinthelimitcaseofhighlysparseconnections,p(cid:28)1.TheR-RBMmodelex-hibitsaninterestinglimitbehaviour,whichwecallhere-aftercompositionalphase.Inthisregimethenumberofstronglymagnetizedhiddenunitsisunbounded,anddi-vergesasL=‘/p,with‘>0andﬁnite.ThenormalizedGSenergye‘=EGS(L=‘/p)/pisanonmonotonousfunctionoftheindex‘,seeFig.4(a).Minimizationofe‘leadstotheselectionofawelldeﬁnedindex‘∗.Themag-netizationsofthe‘∗/pstronglyactivatedunits,m=p2˜m,vanishlinearlywithp[26].Nonmagnetizedhiddenunitshaveactivitiesoftheorderof√r∼√p,andcanbeshut-downbychoosingthresholdsθ∼√p;hencecrosstalkbe-tweenthoseunitscanbesuppressed,allowingforlargerelativesizeαofthehiddenlayer.Theinputreceivedbyavisibleunitfromthelargenumberofmagnetizedunitsis,aftertransmissionthroughthediluteweights,oftheorderofLmp=12‘∗˜mp;itcanbemodulatedbya(positiveornegative)ﬁeldg∼ptoproduceanyﬁniteactivityqinthevisiblelayer,assoonastheeﬀectivetemperaturegetsbelow∼p.Thecompositionalphasecompeteswiththeferromag-neticphase,inwhich˜m>0bute‘isamonotonously4growingfunctionof‘(hence,‘∗=0),andthespinglassphase,inwhich˜m=0ande‘doesnotdependon‘,seeFig.4(a).Thephasediagramintheparameterspace(α,˜g=gp,˜θ=θ√p)willbedetailedin[20].Brieﬂyspeak-ing,givenα,˜θshouldbelargeenough(asinFig.3)and|˜g|shouldbeneithertoolargetopenalizetheferromag-neticphase,nortoosmalltoavoidthespinglassregime.FIG.4:(a).BehaviouroftheGSenergye‘vs.‘=L×pinthep→0limit.Parameters:˜θ=1.5,α=0.5.(b)-(c)-(d).QuantitativepredictionsinthecompositionalregimeofR-RBMcomparedtoRBMsinferredonMNIST.EachpointrepresentaReLURBMtrainedwithvariousregularizations,yieldingdiﬀerentweightsparsitiesp.Solidlinesdepictpre-dictionsfoundbyoptimizinge‘(2),anddashedlineexpectedﬂuctuationsatﬁnitesize(N)andtemperature.(b)Aver-agenumberLofactivehiddenunitsvs.p.(c)Averagemagnetization˜mvs.‘=L×p.(d)Distance(perpixel)be-tweenthepairsofvisibleconﬁgurationsafterconvergenceofzero-temperatureMCMCvs.relativedistancesinthehidden-unitactivationpatterns.MCMCareinitializedwithallpairsofdigitsinMNIST;ﬁnalvisibleconﬁgurationsdiﬀerfromMNISTdigitsbyabout7pixels,bothonthetrainingandtestsets,seeSupplementalMaterial,Fig.1.Inallfourpanelspre-dictionsforthehomogeneous(˜g=−0.21)andheterogeneous(˜g=−0.1725,seeSupplementalMaterial,SectionIII.E)casesareshownin,respectively,cyanandmagenta.CharacteristicpropertiesofourcompositionalphaseareconfrontedtoReLURBMstrainedonMNISTinFig.4(b,c).ComparedtoFig.2weaddaregulariza-tionpenalty∝Pµ(Pi|wiµ|)xtocontroltheﬁnaldegreeofsparsity;thecasex=1givesstandardL1regular-ization,while,forx>1,theeﬀectivepenaltystrength∝(Pi|wiµ|)x−1increaseswiththeweights,hencepro-motinghomogeneityamonghiddenunits.Aftertrain-ingwegenerateMonteCarlosamplesofeachRBMatequilibrium,andmonitortheaveragenumberofactivehiddenunits,ˆL,andthenormalizedmagnetization,˜m.Figure4(b)showsˆLvs.ˆp,ingoodagreementwiththeR-RBMtheoreticalscalingL∼‘?p.Figure4(c)showsthat˜misadecreasingfunctionof‘=ˆL×ˆp,asqualita-tivelypredictedbytheory,butquantitativelydiﬀersfromthepredictionofR-RBMwithhomogeneousp.Thisdis-agreementcanbepartlyexplainedbytheheterogeneitiesinthesparsitiespiinRBMstrainedonMNIST,e.g.unitsonthebordersareconnectedtoonlyfewhiddenunits,whereasunitsatthecenterofthegridareconnectedtomany.WeintroduceaheterogeneousR-RBMmodel,wherethedistributionofthepi’sisﬁttedfromMNIST-trainedRBMs(SupplementalMaterial,SectionIII.E).ItsGSenergycanbecalculatedfrom(2),seeFig.4(a)[20].ResultsareshowninFig.4(b,c)tobeingoodagreementwithRBMtrainedonMNIST.RBMs,unliketheHopﬁeldormixturemodel,maypro-ducegraduallydiﬀerentvisibleconﬁgurationsthroughprogressivechangesinthehidden-layeractivationpat-tern.R-RBMsenjoythesameproperty.Wecompute,throughareal-replicaapproach[20],theaverageHam-mingdistanced(perpixel)betweenthevisibleconﬁg-urationsv(1),v(2)minimizingtheenergyE(1)fortwohiddenconﬁgurationsh(1),h(2)sharing(‘−δ‘)/phid-denunitsamongthe‘/pstronglyactivatedones.Fig-ure4(d)showsthatdmonotonouslyincreasesfromd=0forδ‘=0uptod=2q(1−q)(completedecorrelationofvisibleunits)forδ‘=‘,inverygoodquantitativeagreementwithresultsforRBMtrainedonMNIST.Thegradualchangepropertyhasdeepdynamicalcon-sequences.MCMCofMNIST-trainedRBM(videosavailableinSupplementalMaterial)showthatgradualchangesmayoccasionallyleadtoanotherdigittype,bypassingthroughwell-drawn,yetambiguousdigits.Theprogressivereplacementoffeature-encodinghiddenunits(smallδ‘steps)alongthetransitionpathdoesnotin-creasemuchtheenergy,andthetransitionprocessisfastcomparedtoactivatedhoppingbetweendeepminimatakingplaceintheHopﬁeldmodel.Ourstudyisrelatedtoseveralpreviousworks.RBMswithlinearactivationfunctionΦcoincidewiththeHop-ﬁeldmodel.Inthisframeworkmagnetizedhiddenunitsidentifyretrievedpatterns,andαcorrespondstothecapacityoftheautoassociativememory.TsodyksandFeigel’manshowedhowthecriticalcapacity(forsinglepatternretrieval)couldbedramaticallyincreasedwithsparseweights(p(cid:28)1)andappropriatetuningoftheﬁeldsgi[21];howeverthiseﬀectcouldbeachievedonlywithvanishinglylowactivitiesq.Agliariandcollabora-torsshowedinaseriesofpapers[17,18]thatmultiplesparsepatternscouldbesimultaneouslyretrievedinthecaseoflinearΦandvanishingcapacityα=0(ﬁniteM).Finitecapacityα∼c−2couldbeachievedatzero5temperatureinthelimitofextremesparsity,p=c/N,only[19];forMNISTp’0.1andN=784wouldgiveα∼2.10−4.Ourworkshowsthatlargevaluesofαcanbereachedevenwithmoderatesparsityp(asinrealisticsituations,seeFig.2)providedthatnonlinearΦ(ReLU)andappropriatethresholdvaluesθareconsidered.Thepresenceoftheﬁeldsgiactingonthevisibleunits(absentinthevi=±1modelof[17–19]),isalsocrucialfortheexistenceofourcompositionalphaseasexplainedabove.Itwouldbeinterestingtoextendourworktomorethanonelayersofhiddenunits,ortoothertypesofnonlinearΦ.WhilenumericalstudiesofRBMswithBernoullihiddenunitsshownoqualitativechangecom-paredtoReLU,choosingΦ(h)growingasymptoticallyfasterthanhcouldaﬀectthenatureoftheextractedfeatures[23].Animportantchallengewouldbetoun-derstandthetrainingdynamics,i.e.howhiddenunitsgraduallyextractfeaturesfromdataprototypes.Acknowledgements.WearegratefultoC.FisherandG.Semerjianforusefuldiscussions.ThisworkwaspartlyfundedbytheCNRS-InphynitiInferneuroandtheHFSPRGP0057/2016projects,andbeneﬁtedfromthesupportofNVIDIACorporationwiththedonationofaTeslaK40GPUcard.[1]Y.LeCun,Y.Bengio,J.Hinton,Nature521,436-444(2015).[2]Y.Bengio,A.Courville,P.Vincent,IEEEtransactionsonpatternanalysisandmachineintelligence35,1798-1828(2013).[3]P.Smolensky,Chapter6:InformationProcessinginDy-namicalSystems:FoundationsofHarmonyTheory,inParallelDistributedProcessing:ExplorationsintheMi-crostructureofCognition,Volume1:Foundations,MITPress,194-281(1986).[4]R.Salakhutdinov,A.Mnih,G.Hinton,Proceedingsofthe24thinternationalconferenceonMachinelearning,p.791-798(2007).[5]G.Hinton,Momentum9,926(2010).[6]T.Tieleman,Proceedingsofthe25thinternationalcon-ferenceonMachinelearning,pp.1064-1071(2008).[7]G.Desjardins,A.Courville,Y.Bengio,P.Vincent,O.Delalleau,Proceedingsofthe13thInternationalConfer-enceonArtiﬁcialIntelligenceandStatistics,pp.145-152(2010).[8]M.Gabrie,E.W.Tramel,F.Krzakala,AdvancesinNeu-ralInformationProcessingSystems,pp.640-648(2015).[9]A.Fischer,C.Igel,IberoamericanCongressonPatternRecognition,pp.14-36(2012).[10]A.Barra,A.Bernacchia,E.Santucci,P.Contucci,NeuralNetworks34,1-9(2012).[11]J.J.Hopﬁeld,Proc.Nat.Acad.Sci.USA79,2554(1982).[12]V.Nair,G.E.Hinton,Proceedingsofthe27thInter-nationalConferenceonMachineLearning,p.807-814(2010).[13]A.Treves,J.Comp.Neurosci.2,259-272(1995).[14]Y.LeCun,C.Cortes,C.J.Burges,TheMNISTdatabaseofhandwrittendigits(1998).[15]B.A.Olshausen,D.J.Field,Nature381,607-609(1996).[16]D.J.Amit,H.Gutfreund,H.Sompolinsky,Phys.Rev.Lett.55,1530(1985).[17]E.Agliari,A.Barra,A.Galluzzi,F.Guerra,F.Moauro,Phys.Rev.Lett.109,268101(2012).[18]E.Agliari,A.Annibale,A.Barra,A.C.C.Coolen,D.Tantari,J.Phys.A46,415003(2013).[19]P.Sollich,D.Tantari,A.Annibale,A.Barra,Phys.Rev.Lett.113,238106(2014).[20]J.Tubiana,R.Monasson,inpreparation(2017).[21]M.Tsodyks,M.V.Feigel’man,Europhys.Lett.6,101-105(1989).[22]R.Salakhutdinov,I.Murray,Proceedingsofthe25thin-ternationalconferenceonMachinelearning,pp.872-879(2008).[23]D.Krotov,J.J.Hopﬁeld,arXiv:1606.01164(2016).[24]SeeSupplementalMaterial[url],whichincludesRef[25].[25]TheanoDevelopmentteamTheanoDevelopmentTeam.arXiv:1605.02688.(2016).[26]Solutionswithnonhomogeneousmagnetizationsmµ,varyingfromonestronglyactivatedhiddenunittoan-other,giveadditionalcontributionstoEGSoftheorderofp2withrespecttothehomogeneoussolutionmµ=m,anddonotaﬀectthevalueofe‘[20].SupplementalMaterialEmergenceofCompositionalRepresentationsinRestrictedBoltzmannMachinesJ.Tubiana,R.MonassonI.TRAININGRBMSONMNISTA.Datasetpreparationandinitialconditions•InMNIST,eachpixelhasavaluebetween0and255.Webinarizeitbythresholding≥128.The28×28binaryimagesareﬂattenedtoaN=784vectorwithbinaryvalues.•Thedatasetissplitinatraining(60,000instances)andatest(10,000instances)sets•Theweightswiµarerandomlyinitializedat±W,whereW=q0.1N;thischoicecorrespondstoinitialtemperatureandweightsparsity:T(0)=10andp(0)=1(seesectionIII).•Theinitialﬁeldvaluesareg0i=loghhviiMNIST1−hviiMNISTi,wherehviiMNISTdenotestheaverageofpixelioverthetrainingdata•ForReLU,thethresholdsθµareallinitiallysetto0B.LearningalgorithmsARBMisassociatedtoaprobabilitydistributionP[v,h)=e−E[v,h]Z,wheretheenergyEisdeﬁnedinthemaintext.Themarginaldistribution,P[v]=RQdhµP[v,h)isﬁttedtothedatabylikelihoodmaximization.Givendatainstancesxr,r∈{1,D},thelog-likelihoodis:logLW,g,θ=1DDXr=1log[P[xr|W,g,θ|](1)WhereWisthematrixofweights,gisthevectorofvisiblelayerﬁeldsandθisthevectorofhiddenunitsthresholds.Likelihoodmaximizationisimplementedbystochasticgradientdescent,withthediﬃcultythatextensiveMonteCarlosimulationsarerequiredtocomputethegradient[1,2].FortheRBMofFig.2inthemaintext,weusedPersistentContrastiveDivergence[3]with•20mini-batchsize•100persistentchains•1Gibbsstepbetweeneachupdate•200epochs(600000updatesintotal)•Initiallearningrateofλi=510−3,decayinggeometrically(decaystartsafter60epochs)toλf=510−4PCDisknowntobeinaccuratetowardtheendoflearning,becausetheparametersevolvetoofastwithrespecttothethemixingrateoftheMarkovchains.TheregularizedRBMofmaintext,Fig.4(b,c),weretrainedwithamoreeﬃcientalgorithm,variantofAdaptiveParallelTempering[4,5]with•100mini-batchsize•100persistentchains•10replicasarXiv:1611.06759v2  [physics.data-an]  2 Mar 20172FIG.1:(a)Evolutionthroughouttrainingofthedataloglikelihood(leftscale)andpseudo-loglikelihood(rightscale)computedoverthetrainingandtestsets.(b)EvolutionofthenumberofdistinctlocalmaximaofPW(v)(leftscale)andthedistancetotheoriginalsample(rightscale,fortrainandtestset)aredisplayed.•1Gibbsstepbetweeneachupdate•150epochs(90000updatesintotal)•Initiallearningrateofλi=10−2,decayinggeometrically(decaystartsafter90epochs)toλf=10−4C.MonitoringthelearningWemonitortheevolutionofthelikelihoodandofthepseudo-likelihoodofthetrainandtestdatasetsthroughoutlearning,seeFig.1(a).Thechoiceofparametersmadelearningslow,butensuredthatthelikelihoodincreasedsteadilythroughouttraining.Thelikelihoodrequiresapproximatecomputationofthemodelpartitionfunction;AnnealedImportanceSampling[6]wasused.Parameters:nβ=10000inversetemperatureswithanadaptivespacing[5],nruns=1.Additionnaly,wecanlookattheprobabilitylandscapePW(v)throughoutlearning.Foreachofthe70kMNISTsamples,agradientascentonPW(v)isperformeduntilconvergencetoalocalmaximum;thenumberofdistinctlocalmaximaofPW(v)andthedistancetotheoriginalsamplearemeasured.Astraininggoes,morelocalmaximaappear,andtheygetclosertothetrainingsamples;localmaximaalsoappearclosetothetestset,whichshowsthatRBMgeneralizewell.D.ControlingweightsparsitywithregularizationTocontroltheweightsparsityp,aregularizationpenaltyisaddedtotheloglikelihoodlogLW,g,θ:Cost=−logLW,g,θ+L(x)L(x)=λxxXµ"Xi|wiµ|#x−∂Cost∂wiµ=∂∂wiµlogLW,g,θ−λxXj|wjµ|x−1sign(wiµ)(2)Thecasex=1istheusualL1penaltyandperforminggradientdescentwithλ1>0isknowntoreducethenumberofnon-zeroweightswiµ.However,experimentsshowthattheoutcomeisinhomogeneouswithrespecttothehiddenunits:somehiddenunitsareweaklyaﬀectedbythepenalty,whereassomeendupcompletelydisconnectedfromthevisiblelayer,makingthemuseless,seeFig.2.Tomaintainhomogeneityamongthehiddenunits,wepickx=2orx=3.Ascanbeseenfromtheexpressionofthegradient,itisequivalenttoausualL1penalty,butwithadecayrateadaptivetoeachhiddenunit:hiddenunitsstrongly(resp.weakly)coupledtothevisiblelayer(largePi|wiµ|)arestrongly(resp.weakly)regularized,thusincreasingthehomogeneityamonghiddenunits.3FIG.2:Subsetof12weightfeaturesproducedbytrainingonMNIST,regularizedwithL1,λ1=10−3(toppanel),andL2,λ2=3.10−5(bottompanel).Bothhaveoverallsparsityp∼0.036,butthelatterismorehomogeneouslydistributedacrosshiddenunits.FIG.3:SixindependentMonteCarloMarkovChainsrealizationforaRBMtrainedonMNIST,extractedfromtheattachedvideos,seetext.II.SAMPLINGFROMRBMSRBMcanbesampledbyMarkovChainsMonteCarlo.Duetotheconditionalindependenceproperty,GibbssamplingcanbeperformedbyalternativesamplingofhfromP[h|v],thenvfromP[v|h][1,2].A.MCMCVideosThetwovideosinSupplementaryMaterialpresentvisualizeMCMCrunsfromRBMtrainedonMNISTwithBernoulli,Gaussian,ReLUhiddenunits.EachsquaredepictsaMarkovchainstartedfromarandominitialcondition.20Gibbsstepsareperformedbetweeneachimage,andeachchainis500imageslong.SeeFig.3forasnapshot.4FIG.4:TenMonteCarloMarkovChainsrealizationsatdiﬀerentinversetemperatures,coupledbyreplicaexchange.Theplotsshowstheconditionalexpectationsofvisibileunits,E[v|h],forthermalizedhidden-unitactivities,h.B.EstimatingthermalaverageswithMCMCSamplingatthermalequilibriumisrequiredtoestimatethevaluesoforderparameters(L,S,q,˜m,...).SinceRBMtrainedonMNISTeﬀectivelyoperateatlowtemperature(entropyof0.1bits/pixel)theMCMCmixingrateispoor,andlongsimulationswouldberequiredforeachofthe∼100RBMstrained.ToovercomethisissueweuseanAdaptiveParallelTempering(alsoknownasReplicaExchange)samplingalgorithm,with10replicas[4,5].Observablesareaveragedover100independentMarkovChains,eachbeingﬁrstthermalizedfor500Gibbsupdates,thenrunforanother100Gibbsupdates(10Ksamplesintotal).C.EstimatingorderparametersofR-RBMwithzerotemperatureMCMCR-RBMarestudiedanalyticallyinthezero-temperaturelimit;thislimitcanbesimulatedaswell.TheenergyE[v,h]ofaconﬁgurationv,hisgivenbyEqn.(1)inmaintext,anddeﬁnestheGibbsdistributionPβ[v,h]=exp(−βE[v,h]/Z(β),whereβ=1Tistheinversetemperature.Asβincreases,Pβ[v,h]ismoreandmorepeakedaroundtheminimumofE.Inthelimitβ→∞,adynamicalGibbsstepbecomesdeterministic:hµ←argminh"Uµ(h)−hXiwµivi#≡Φµ"Xiwiµvi#vi←argminv"−giv−vXµwµihµ#≡Θ"gi+Xµwiµhµ#,(3)whereΘistheHeavisidefunction,andΦµistheresponsefunction(Fig.1(b)inmaintext).Startingfromaconﬁgu-ration,suchzero-temperatureMarkovChainrunsuntilconvergencetoalocalminimumofE.Inpractice,tomakeﬁnite-sizecorrectionstoourmean-ﬁeldtheorysmall,weconsideredRBMswithuptoN∼104visibleunits.SuchlargeR-RBMweresimulatedusinganVidiaTeslaK40GPU,programmedwithTheano[7].5D.FindinglocalmaximaofP[v]GivenanRBMwithenergydeﬁnedasabove,themarginalP[v]ischaracterizedbyaGibbsdistributionandafreeenergy:P[v]=ZYµdhµ1Ze−E[v,h]=1Ze−F[v]F[v]=−Xigivi+XµUeffµ Xiwiµvi!Ueffµ(x)=−log(cid:20)Zdhe−Uµ(h)+xh(cid:21)(4)InordertoﬁndthelocalmaximaofP[v](i.e.thelocalminimaofF[v]),wemodifyitbyintroducinganinversetemperatureβ:Pβ[v]=1Z(β)e−βF[v]Z(β)=Xve−βF[v](5)Samplingfromthisdistributionatβ6=1isnottrivial,asPβ[v]isnotthemarginaldistributionofPβ[v,h]whenβ6=1.WhilesamplingfromP1[v]iseasy,asonecansimplysamplefromthejointdistributionP1[v,h]usingGibbssteps,thisisnottrueforβ6=1;inparticularthelocalmaximaofPβ[v,h]arenotequivalenttothoseofPβ[v].Wenoticehoweverthatwhenβ≥1isaninteger,Pβ[v]canbeinterpretatedastheβ=1distributionofanotherRBMP01[v]withβMhiddenunits(eachhiddenunitisreplicatedβtimes)andvisibleﬁeldsg0=βg.SamplingfromsuchRBMcanbedoneasfollowing:•ComputethehiddenlayerinputsPiwiµvi•SampleindependentlyβreplicashrµofhµfromP1[hµ|v]•ComputethevisiblelayerinputsIi=Pβr=1Pµwiµhrµ•SamplevifromtheBernoullidistributionBernhβ(gi+1βIi)iWhenβ→∞,1βPβr=1hrcoincideswiththeconditionalaverageofhgivenv,E[h|v].Therefore,thezerotemper-aturesamplingGibbsstepforthefreeenergyisequivalentto:hµ←E[hµ|v]vi←Θ"gi+Xµwiµhµ#(6)III.NUMERICALPROXIESFORCONTROLANDORDERPARAMETERSSeveralcontrolandorderparametersarewelldeﬁnedforR-RBMinthethermodynamicallimit,butnotfortypicalRBMtrainedondata.ForR-RBMinstances,theaverageweightsparsitypiswelldeﬁnedbecausetheweightstakeonlythreedistinctvalues{−1√N,0,1√N},butforRBMtrainedondata,theweightswiµareneverexactlyequaltozero.Similarly,thenumberofstronglyactivatedhiddenunitsLiswell-deﬁnedforR-RBMinthethermodynamiclimitN→∞becausetheiractivityscalesas√N;butingeneral,allhiddenunitshaveﬁniteactivation.Proxiesarethereforerequiredtocomparetheoreticalandnumericalresults.Weconsider’consistent’proxies,givingback(inthelargesizelimit),theoriginalparametersforRBMsdrawnfromtheR-RBMensemble.6A.ParticipationRatiosPRParticipationratiosareusedtoestimatenumbersofnonzerocomponentsinavector,whileavoidingtheuseofarbitrarythresholds.TheParticipationRatio(PRa)ofavectorx={xi}isPRa(x)=(Pi|xi|a)2Pi|xi|2aIfxhasKnonzeroandequal(inmodulus)componentsPRisequaltoKforanya.Inpracticeweusethevaluesa=2and3:thehigherais,themoresmallcomponentsarediscountedagainststrongcomponentsinx.B.NumberLofactivehiddenunitsInbothnumericalsimulationsofR-RBMandonRBMtrainedonMNIST,weestimateL,foragivenhidden-unitconﬁgurationh,throughˆL=PR3(h)Tounderstandthechoicea=3,consideratypicalactivationconﬁgurationhforaR-RBM:hµ=(cid:26)m√Nif1≤µ≤L,√rxµifL+1≤µ≤M,(7)wherethemagnetizationmandmeansquareactivityrareO(1),andxµarerandomvariableswithzeromean,andevenmomentsoftheorderofunity.TheﬁrstLhiddenunitsarestronglyactivated(O(√N)activity),whereastheremainingN−Lothersarenot(activationsoftheorderof1).Here,weassumeLtobeﬁniteasN→∞.Onecomputes:PR2(h)∼(Lm2N+(N−L)r)2Lm4N2+(N−L)r2=L×(1+N−LNrLm2)21+N−LN2r2Lm4−→N→∞L(1+rLm2)2,PR3(h)∼(Lm3N3/2+(N−L)r3/2)2Lm6N3+(N−L)r3=L×(1+N−LN3/2r3/2Lm3)21+N−LN3r3Lm6−→N→∞L.(8)Hencechoosingcoeﬃcienta=3ensuresthattheparticipationratio(a)doesnottakeintoaccounttheweakactivationsinthethermodynamicallimit,and(b)convergestothetruevalueLifallmagnetizationsareequal.C.NormalizedMagnetizations˜mGivenaRBMandavisiblelayerconﬁguration,wedeﬁnethenormalizedmagnetizationofhiddenunitµasthenormalizedoverlapbetweentheconﬁgurationandtheweightsattachedtotheunit:˜mµ=Pi(2vi−1)wiµPi|wiµ|∈[−1,1]ThisdeﬁnitionisconsistentwiththeHopﬁeldmodel.ForR-RBM,wealsohave,inthethermodynamicallimit,ˆmµ=2Iµp√N,whereIµistheinputreceivedbythehiddenunitfromthevisiblelayer;mµisO(1)forstronglyactivatedhiddenunits,andO(1√N)fortheothers.Foragivenconﬁgurationv,withˆLactivatedhiddenunits,thenormalizedmagnetizationoftheactivatedhiddenunits˜m=mp/2canbeestimatedastheaverageoftheˆLhighestmagnetizationsˆmµ.D.WeightsparsitypAnaturalwaytoestimatethefractionofnon-zeroweightswiµwouldbetocountthenumberofweightswithabsolutevalueabovesomethresholdt.However,thereisnosimplesatisfactorychoicefort.Indeed,thefractionof7FIG.5:(a)Histogramof˜pi=pipvalues,acrossallvisibleunitsandRBMsinferredonMNIST.(b)AverageacrossallRBMof˜pi=pip,foreachvisibleunitnon-zeroweightsshouldnotdependonthescaleoftheweights,i.e.itshouldbeinvariantundertheglobalrescalingtransformation{wiµ}→{λwiµ}.AsthescaleofweightsvaryfromRBMstoRBMsand,foreachRBM,acrosstrainingitappearsdiﬃculttoselectanappropriatevaluefort.ApossibilitywouldbetouseathresholdadaptedtoeachRBM,e.g.t∝κqW2M,whereκwouldbesomesmallnumber.Ourexperimentsshowthatitisnotaccurateenough,duetothescaledisparitiesacrossthehidden–unitweightvectorswµ.RatherthanadaptingthresholdstoeachhiddenunitofeachRBM,weuseParticipationRatios,whichnaturallyenjoythescaleinvarianceproperty.Weestimatethefractionofnonzeroweightsthroughˆp=1MNXµPR2(wµ)ForR-RBMwithwiµ∈[−W0,0,W0]withcorrespondingprobabilities[p2,1−p,p2],theestimatorisconsistent:ˆp=p.E.WeightsheterogeneitiesAsseenfromthefeaturesofFig.2inthemaintext,notallvisibleunitsareequallyconnectedtothehiddenlayer.Tobettercapturethiseﬀect,onecanstudyR-RBMwithanyarbitrarydistributionofpi.Analogouslytothehomogeneouscaseahighsparsitylimitisobtainedwhentheaveragesparsity,p=1NPipi,vanishes.Wedeﬁnethedistributionoftheratios˜pi=pipinthep→0limit.Inpracticetheratiosareestimatedthrough˜pi=Piw2iµ1MPi,µw2iµ.(9)ForaheterogeneousR-RBM,wehaveconsistently˜pi=ˆpip=pip.Lookingatthehistogramofvaluesof˜piacrossallRBMinferredonMNIST,weﬁndanon-negligiblespreadaroundone,seeFig.5.Wealsodisplayforeachvisibleunititheaverageof˜piaccrossallRBMinferred;wecanseethatthevisibleunitsattheborderareindeedtheleastconnected(smaller˜pi),whereastheonesatthecenterarestronglyconnected(larger˜pi).F.EﬀectiveTemperatureTAlthoughRBMdistributionsarealwaysdeﬁnedattemperatureT=1,theeﬀectivetemperatureisnot1.ThisisverymuchlikeintheIsingmodel:thebehaviorofthesystemdependsonaneﬀectivetemperatureˆT=TJwhere8FIG.6:ConditionalmeansE[v|h]fortwohiddenunitsconﬁgurationssampledatequilibrium.Mostpixelsviarefrozen,withE[vi|h]∈{0,1}Jisthecouplingstrength;aloweﬀectivetemperaturephasecorrepondtohighvaluesofJ.ForReLURBM,theprobabilitydistributionofconﬁgurationsattemperatureTisdeﬁnedas:Pw[v,h]=e−E[v,h]TwithE[v,h]T=−XigiTvi+Xµ h2µ2T+hµθµT!−Xi,µwiµTvihµ.(10)Let¯h=h√T.TheprobabilitycanberewrittenasP[v,¯h]=e−¯E[v,¯h]with¯E(v,¯h)=−XigiTvi+Xµ ¯h2µ2+¯hµθµ√T!−Xi,µwiµ√Tvi¯hµ.(11)SincethemarginalP[v]isnotaﬀectedbythechangeofvariable,aReLURBMattemperatureTisthereforeequivalenttoanotherReLURBMattemperatureT=1,withnewﬁelds,thresholdsandweights:¯g=gT,¯θ=θ√T,¯w=w√T.Therefore,changingthetemperatureisequivalenttorescalingtheparameters,andinturn,theeﬀectivetemperatureofagivenRBMcanbededucedfromtheamplitudeofitsweights.ForaR-RBMattemperatureT:W2=1MXµ,i¯w2iµ∼N→∞pT.WethereforeestimatethetemperatureofagivenRBMthroughˆT=ˆp1MPµ,iw2iµ.Fromthisdeﬁnition,itcanbeseenthatthelowtemperatureregimeofthecompositionalregime,T(cid:28)p,isequivalenttoW2(cid:29)1.InRBMtrainedonMNIST,wetypicallyﬁndW2∼7G.FieldsgSimilarlytotheweights,theﬁeldsgiandnormalizedﬁeldscouldbeestimatedrespectivelyas:ˆgi=ˆT¯giˆ˜gi=ˆTˆp¯gi=¯gi1MPµ,iw2iµ(12)Anaiveestimateforthenormalizedﬁeld˜gwouldbetoaveragetheﬁelds:ˆ˜g=1NPiˆ˜gi.Itishowevernotreallymeaningful,astheˆ˜giareextremelyheterogeneous:forinstance,themeanvalueoverthesitesiofasingleRBMis9equalto−0.48,andiscomparabletothestandarddeviation,0.40.ThisrangeofvariationspansallthephasesofR-RBM.Toachievequantitativepredictions,weinsteadadjusttheR-RBMparametergsothatq,themeanvalueofviinthevisiblelayer,averagedoverthermalﬂuctuationsandquencheddisorder,matchesthevalue0.132obtainedfromMNISTdata.FortheplotsofFigure4inthemaintext,thisgivesˆgˆp=−0.1725forhomogeneousR-RBM,andˆgˆp=−0.21forheterogeneousR-RBM.H.ThresholdsθThethresholdsandnormalizedthresholdscanbeestimatedasˆθµ=pˆT¯θµˆ˜θµ=sˆTˆp¯θµ=¯θµq1MPµ,iw2iµ(13)Again,anaiveestimateforthenormalizedthreshold˜θwouldbetheaverageˆ˜θ=1MPµˆ˜θµbutthisestimateisnotmeaningful.Indeed,contrarytotheR-RBMcase,theinputsIµofthehiddenunitsµarenotevenlydistributedaroundzero:E[Iµ]6=0.Hence,evenifthethresholdisequaltozero,theactivationprobabilitycanbediﬀerentfrom0.5.Wetakethiseﬀectintoaccountbysubstractingtheaveragevalueoftheinputsfromtheaverageofθ,andﬁndthatthediﬀerenceisequalto0.33,withstandarddeviation1.11.Thisrangeofvalueforθagainspansallphases.Inordertouseawell-deﬁnedvalue,wechooseθsuchthatthecriticalcapacityαR−RBMc(‘max)=0.5,where‘max∼1.5isthemaximumaverageindexnumberobservedacrossallRBMstrainedforFig.4inthemaintext.Thisestimationgivesˆ˜θ∼1.5.[1]A.Fischer,C.Igel.IberoamericanCongressonPatternRecognition,pp.14-36(2012).[2]G.Hinton.Momentum9,926(2010).[3]Tieleman,T.Proceedingsofthe25thinternationalconferenceonMachinelearning,pp.1064-1071(2008,July).[4]Desjardins,G.,Courville,A.,Bengio,Y.,Vincent,P.,Delalleau,O.Proceedingsofthe13thInternationalConferenceonArtiﬁcialIntelligenceandStatistics,pp.145-152(2010).[5]J.Tubiana,R.Monasson,inpreparation(2017).[6]Salakhutdinov,R.,&Murray,I.InProceedingsofthe25thinternationalconferenceonMachinelearning(pp.872-879).(2008,July)[7]TheanoDevelopmentTeam.Theano:APythonframeworkforfastcomputationofmathematicalexpressions,arXivpreprintarXiv:1605.02688.(2016).