Chains of Reasoning over Entities, Relations, and Text using

Recurrent Neural Networks

Rajarshi Das, Arvind Neelakantan, David Belanger, Andrew McCallum

College of Information and Computer Sciences

{rajarshi, arvind, belanger, mccallum}@cs.umass.edu

UMass, Amherst

6
1
0
2

 
t
c
O
3
1

 

 
 
]
L
C
.
s
c
[
 
 

2
v
6
2
4
1
0

.

7
0
6
1
:
v
i
X
r
a

Abstract

Our goal is to combine the rich multi-
step inference of symbolic logical reason-
ing with the generalization capabilities of
neural networks. We are particularly in-
terested in complex reasoning about enti-
ties and relations in text and large-scale
knowledge bases (KBs). Neelakantan et
al. (2015) use RNNs to compose the dis-
tributed semantics of multi-hop paths in
KBs; however for multiple reasons, the
approach lacks accuracy and practical-
ity. This paper proposes three signiﬁ-
cant modeling advances: (1) we learn to
jointly reason about relations, entities, and
entity-types; (2) we use neural attention
modeling to incorporate multiple paths;
(3) we learn to share strength in a sin-
gle RNN that represents logical compo-
sition across all relations. On a large-
scale Freebase+ClueWeb prediction task,
we achieve 25% error reduction, and a
53% error reduction on sparse relations
due to shared strength. On chains of rea-
soning in WordNet we reduce error in
mean quantile by 84% versus previous
state-of-the-art.1.

Introduction

1
There is a rising interest in extending neural net-
works to perform more complex reasoning, for-
merly addressed only by symbolic and logical rea-
soning systems. So far this work has mostly fo-
cused on small or synthetic data (Grefenstette,
2013; Bowman et al., 2015; Rockt¨aschel and
Riedel, 2016). Our interest is primarily in reason-
ing about large knowledge bases (KBs) with di-

1The

code

and

data

are

available

at

https://rajarshd.github.io/ChainsofReasoning/

i. place.birthpa, bq Ð ‘was born in’pa, xq^
‘commonly known as’px, bq
ii. location.containspa, bq Ð (nationality)´1pa, xq^
place.birthpx, bq
iii. book.characterspa, bq Ð‘aka’pa, xq^
(theater.character.plays)´1px, bq
iv. cause.deathpa, bq Ð‘contracted’pa, bq

Table 1: Several highly probable clauses learnt
by our model. The textual relations are shown in
quotes and italicized. Our model has the ability to
combine textual and schema relations. r´1 is the
inverse relation r, i.e. rpa, bq ô r´1pb, aq.

verse semantics, populated from text. One method
for populating a KB from text (and for repre-
senting diverse semantics in the KB) is Universal
Schema (Riedel et al., 2013; Verga et al., 2016),
which learns vector embeddings capturing the se-
mantic positioning of relation types - the union of
all input relation types, both from the schemas of
multiple structured KBs, as well as expressions of
relations in natural language text.

An important reason to populate a KB is to
support not only look-up-style question answer-
ing, but reasoning on its entities and relations in
order to make inferences not directly stored in
the KB. KBs are often highly incomplete (Min
et al., 2013), and reasoning can ﬁll
in these
missing facts. The “matrix completion” mecha-
nism that underlies the common implementation
of Universal Schema can thus be seen as a sim-
ple type of reasoning, as can other work in ten-
sor factorization (Nickel et al., 2011; Bordes et
al., 2013; Socher et al., 2013). However these
methods can be understood as operating on sin-
gle pieces of evidence: for example, inferring that
Microsoft–located-in–Seattle implies Microsoft–

(a)

(b)

Figure 1: The nodes in the knowledge graphs represent entities and the labeled edges represent relations.
(a) A path between ‘Melinda’ and ‘Seattle’ combining relations from two different documents. (b) There
are multiple paths between entities in a knowledge graph. The top two paths are predictive of the fact
that Melinda may ‘live in’ Seattle, but the bottom (ﬁctitious) path isn’t.

HQ-in–Seattle.

A highly desirable, richer style of reasoning
makes inferences from Horn clauses that form
multi-hop paths containing three or more enti-
ties in the KB’s entity-relation graph. For ex-
ample, we may have no evidence directly linking
Melinda Gates and Seattle, however, we may in-
fer with some likelihood that Melinda–lives-in–
Seattle, by observing that the KB contains the
path Melinda–spouse–Bill–chairman–Microsoft–
HQ-in–Seattle (Fig. 1a).

Symbolic rules of this form are learned by the
Path Ranking Algorithm (PRA) (Lao et al., 2011).
Dramatic improvement in generalization can be
obtained by reasoning about paths, not in terms
of relation-symbols, but Universal Schema style
relation-vector-embeddings. This is done by Nee-
lakantan et al. (2015), where RNNs semantically
compose the per-edge relation embeddings along
an arbitrary-length path, and output a vector em-
bedding representing the inferred relation between
the two entities at the end-points of the path. This
approach thus represents a key example of com-
plex reasoning over Horn clause chains using neu-
ral networks. However, for multiple reasons de-
tailed below it is inaccurate and impractical.

This paper presents multiple modeling advances
that signiﬁcantly increase the accuracy and prac-
ticality of RNN-based reasoning on Horn clause
chains in large-scale KBs. (1) Previous work, in-
cluding (Lao et al., 2011; Neelakantan et al., 2015;
Guu et al., 2015) reason about chains of relations,
but not the entities that form the nodes of the
path.
Ignoring entities and entity-types leads to
frequent errors, such as inferring that Yankee Sta-
dium serves as a transportation hub for NY state.

In our work, we jointly learn and reason about
relation-types, entities, and entity-types. (2) The
same previous work takes only a single path as ev-
idence in inferring new predictions. However, as
shown in Figure 1b, multiple paths can provide ev-
idence for a prediction. In our work, we use neu-
ral attention mechanisms to reason about multiple
paths. We use a novel pooling function which does
soft attention during gradient step and ﬁnd it to
work better. (3) The most problematic impracti-
cality of the above previous work2 for application
to KBs with broad semantics is their requirement
to train a separate model for each relation-type to
be predicted. In contrast, we train a single, high-
capacity RNN that can predict all relation types.
In addition to efﬁciency advantages, our approach
signiﬁcantly increases accuracy because the multi-
task nature of the training shares strength in the
common RNN parameters.

We evaluate our new approach on a large
scale dataset of Freebase entities, relations and
ClueWeb text.
In comparison with the previous
best on this data, we achieve an error reduction of
25% in mean average precision (MAP). In an ex-
periment specially designed to explore the beneﬁts
of sharing strength with a single RNN, we show a
54% error reduction in relations that are available
only sparsely at training time. We also evaluate on
a second data set, chains of reasoning in WordNet.
In comparison with previous state-of-the-art (Guu
et al., 2015) our model achieves a 84% reduction
in error in mean quantile.

2with exception of (Guu et al., 2015)

January 15, 2000Tech pioneer Bill Gates stepped down today as chief executive officer of Microsoft, the Seattle-headquartered software giant.He will continue to serve as the chairman... Feb 6, 1999William H. Gates,chairman of Microsoft Corp. and his wife Melinda gave $3.3B to their two foundation, the president of one of the foundation said yesterday..SeattleMelindaBillMicrosoftheadquarteredchairmanspouselives in??MelindaGates FoundationChairHQInSeattleSpouseBillJane DoefriendChairTerraPowerHQInBellevuenearbornLives in??abc abc Figure 2: At each step, the RNN consumes both entity and relation vectors of the path. The entity
representation can be obtained from its types. The path vector yπ is the last hidden state. The parameters
of the RNN and relation embeddings are shared across all query relations. The dot product between
the ﬁnal representation of the path and the query relation gives a conﬁdence score, with higher scores
indicating that the query relation exists between the entity pair.

2 Background

In this section, we introduce the compositional
model (Path-RNN) of Neelakantan et al. (2015).
The Path-RNN model
takes in input a path
between two entities and infers new relations
between them. Reasoning is performed non-
atomically about conjunctions of relations in an
arbitrary length path by composing them with a
recurrent neural network (RNN). The representa-
tion of the path is given by the last hidden state of
the RNN obtained after processing all the relations
in the path.
Let pes, etq be an entity pair and S denote
the set of paths between them. The set S is
obtained by doing random walks in the knowl-
edge graph starting from es till et. Let π “
tes, r1, e1, r2, . . . , rk, etu P S denote a path be-
tween pes, etq. The length of a path is the num-
ber of relations in it, hence, plenpπq “ kq. Let
yrt P Rd denote the vector representation of rt.
The Path-RNN model combines all the relations
in π sequentially using a RNN with an intermedi-
ate representation ht P Rh at step t given by

ht “ fpWr

hhht´1 ` Wr

rtq.
ihyr

hh P Rhˆh and Wr

(1)
ih P Rdˆh are the param-
Wr
eters of the RNN. Here r denotes the query rela-
tion. Path-RNN has a specialized model for pre-
dicting each query relation r, with separate param-
eters pyr
ihq for each r. f is the sig-
moid function. The vector representation of path
π pyπq is the last hidden state hk. The similarity of

rt, Wr

hh, Wr

yπ with the query relation vector yr is computed
as the dot product between them:

scorepπ, rq “ yπ ¨ yr

(2)

Pairs of entities may have several paths connecting
them in the knowledge graph (Figure 1b). Path-
RNN computes the probability that the entity pair
pes, etq participates in the query relation prq by,
Ppr|es, etq “ max σpscorepπ, rqq,@π P S (3)
where σ is the sigmoid function.

Path-RNN and other models such as the Path
Ranking Algorithm (PRA) and its extensions (Lao
et al., 2011; Lao et al., 2012; Gardner et al., 2013;
Gardner et al., 2014) makes it impractical to be
used in downstream applications, since it requires
training and maintaining a model for each relation
type. Moreover, parameters are not shared across
multiple target relation types leading to large num-
ber of parameters to be learned from the training
data.

In (??), the Path-RNN model selects the maxi-
mum scoring path between an entity pair to make a
prediction, possibly ignoring evidence from other
important paths. Not only is this a waste of com-
putation (since we have to compute a forward pass
for all the paths anyway), but also the relations in
all other paths do not get any gradients updates
during training as the max operation returns zero
gradient for all other paths except the maximum
scoring one. This is especially ineffective during
the initial stages of the training since the maxi-
mum probable path will be random.

countryofHQ(target relation)Similarity metric0.94d Q Microsoft  isBasedInSeattle  locatedInUSA  (dummy_rel)Washington  locatedIn(Path Vector)The Path-RNN model and other multi-hop
relation extraction approaches (such as Guu
et al. (2015)) ignore the entities in the path.
the following paths JFK–locatedIn–
Consider
NYC–locatedIn–NY and Yankee
Stadium–
locatedIn–NYC–locatedIn–NY. To predict
the
airport serves relation,
the Path-RNN model
assigns the same scores to both the paths even
though the ﬁrst path should be ranked higher. This
is because the model does not have information
about the entities and just uses the relations in the
path for prediction.

3 Modeling Approach
3.1 Shared Parameter Architecture
Previous section discussed the problems associ-
ated with per-relation modeling approaches. In re-
sponse, we share the relation type representation
and the composition matrices of the RNN across
all target relations enabling lesser number of pa-
rameters for the same training data. We refer to
this model as Single-Model. Note that this is just
multi-task learning (Caruana, 1997) among pre-
diction of target relation types with an underlying
shared parameter architecture. The RNN hidden
state in (??) is now given by:

ht “ fpWhhht´1 ` Wihyrtq.

(4)

Readers should take note that the parameters here
are independent of each target relation r.

Model Training
We train the model using existing observed facts
(triples) in the KB as positive examples and un-
observed facts as negative examples. Let R “
tγ1, γ2, . . . , γnu denote the set of all query rela-
tion types that we train for. Let ∆`
R denote
the set of positive and negative triples for all the
relation types in R. The parameters of the model
are trained to minimize the negative log-likelihood
of the data.
LpΘ, ∆`

log Ppr|es, etq

R, ∆´

ÿ

R, ∆´

Rq “ ´ 1
ÿ

M

`

ˆes,ˆet,ˆrP∆´
R

es,et,rP∆`
R

logp 1 ´ Ppˆr|ˆes, ˆetqq

(5)

Here M is the total number of training examples
and Θ denotes the set of all parameters of the

model (lookup table of embeddings (shared) and
parameters of the RNN (shared)).
It should be
noted that the Path-RNN model has a separate loss
function for each relation r P R which depends
only on the relevant subset of the data.

3.2 Score Pooling
In this section, we introduce new methods of score
pooling that takes into account multiple paths be-
tween an entity pair. Let ts1, s2, . . . , sNu be the
similarity scores (Equation ??) for N paths con-
necting an entity pair pes, etq. The probability
for entity pair pes, etq to participate in relation r
(Equation ??) is now given by,

1. Top-(k): A straightforward extension of the
‘max’ approach in which we average the top
k scoring paths. Let K denote the indices of
top-k scoring paths.

Ppr|es, etq “ σp 1
k

sjq,@j P K

ÿ

j

2. Average: Here, the ﬁnal score is the average

of scores of all the paths.

Ppr|es, etq “ σp 1
N

Nÿ

i“1

siq

3. LogSumExp:

In this approach the pooling
layer is a smooth approximation to the ‘max’
function - LogSumExp (LSE). Given a vector
of scores, the LSE is calculated as

LSEps1, s2, . . . , snq “ logp

exppsiqq

ÿ

i

and hence the probability of the triple is,
Ppr|e1, e2q “ σpLSEps1, s2, . . . , snqq

The average and the LSE pooling functions apply
non-zero weights to all the paths during inference.
However only a few paths between an entity pair
ř
is predictive of a query relation. LSE has another
“ exppsiq
desirable property since BLSEBsi
i exppsiq. This
means that during the back-propagation step, ev-
ery path will receive a share of the gradient propor-
tional to its score and hence this is a kind of novel
neural attention during the gradient step. In con-
trast, for averaging, every path will receive equal
Nq share of the gradient. Top-(k) (similar to
p 1
max) receives sparse gradients.

Incorporating Entities

3.3
A straightforward way of incorporating entities is
to include entity representations (along with re-
lations) as input to the RNN. Learning separate
representations of entity, however has some disad-
vantages. The distribution of entity occurrence is
heavy tailed and hence it is hard to learn good rep-
resentations of rarely occurring entities. To allevi-
ate this problem, we use the entity types present in
the KB as described below.

Most KBs have annotated types for entities and
each entity can have multiple types. For exam-
ple, Melinda Gates has types such as CEO, Duke
University Alumni, Philanthropist, American Cit-
izen etc. We obtain the entity representation by a
simple addition of the entity type representations.
The entity type representations are learned during
training. We limit the number of entity types for
an entity to 7 most frequently occurring types in
the KB. Let yet P Rm denote the representation
of entity et, then ?? now becomes
ht “ fpWhhht´1 ` Wihyrt ` Wehyetq (6)
Weh P Rmˆh is the new parameter matrix
for projecting the entity representation. Figure
2 shows our model with an example path be-
tween entities (Microsoft, USA) with country-
OfHQ (country of head-quarters) as the query re-
lation.

4 Related Work
Two early works on extracting clauses and rea-
soning over paths are SHERLOCK (Schoenmack-
ers et al., 2010) and the Path Ranking Algorithm
(PRA) (Lao et al., 2011). SHERLOCK extracts
purely symbolic clauses by exhaustively explor-
ing relational paths of increasing length. PRA re-
places exhaustive search by random walks. Ob-
served paths are used as features for a per-target-
relation binary classiﬁer. Lao et al. (2012) extend
PRA by augmenting KB-schema relations with
observed text patterns. However, these methods do
not generalize well to millions of distinct paths ob-
tained from random exploration of the KB, since
each unique path is treated as a singleton, where
no commonalities between paths are modeled. In
response, pre-trained vector representations have
been used in PRA to tackle the feature explo-
sion (Gardner et al., 2013; Gardner et al., 2014)
but still rely on a classiﬁer using atomic path fea-
tures.Yang et al. (2015) also extract horn rules but

Stats
# Freebase relation types
# textual relation types
# query relation types
# entity pairs
# unique entity types
Avg. path length
Max path length
Total # paths

27,791
23,599

46

#

3.22M
2218
4.7
7

191M

Table 2: Statistics of the dataset.

they restrict it to a length of 3 and are restricted
to schema types. Zeng et al. (2016) show im-
provements in relation extraction by incorporating
sentences which contain one entity by connecting
them through a path.

Guu et al. (2015) introduce new compositional
techniques by modeling additive and multiplica-
tive interactions between relation matrices in the
path. However they model only a single path be-
tween an entity pair in-contrast to our ability to
consider multiple paths. Toutanova et al. (2016)
improves upon them by additionally modeling the
intermediate entities in the path and modeling
multiple paths. However, in their approach they
have to store scores for intermediate path length
for all entity pairs, making it prohibitive to be used
in our setting where we have more than 3M en-
tity pairs. They also model entities as just a scalar
weight whereas we learn both entity and type rep-
resentations. Lastly it has been shown by Nee-
lakantan et al. (2015) that non-linear composition
function out-performs linear functions (as used by
them) for relation extraction tasks.

The performance of relation extraction meth-
ods have been improved by incorporating entity
types for their candidate entities, both in sentence
level (Roth and Yih, 2007; Singh et al., 2013) and
KB relation extraction (Chang et al., 2014), and
in learning entailment rules (Berant et al., 2011).
Serban et al. (2016) use RNNs to generate factoid
question from Freebase.

5 Results
Data and Experimental Setup
We apply our models to the dataset released
by Neelakantan et al. (2015), which is a sub-
set of Freebase enriched with information from
ClueWeb. The dataset is comprised of a set of
triples (e1, r, e2) and also the set of paths con-
necting the entity pair (e1,e2) in the knowledge

graph. The triples extracted from ClueWeb con-
sists of sentences that contained entities linked to
Freebase (Orr et al., 2013). The phrase between
the two entities in the sentence forms the relation
type. To limit the number of textual relations, we
retain the two following words after the ﬁrst en-
tity and two words before the second entity. We
also collect the entity type information from Free-
base. Table 2 summarizes some important statis-
tics. For the PathQA experiment, we use the same
train/dev/test split of WordNet dataset released by
Guu et al. (2015) and hence our results are directly
comparable to them. The WordNet dataset has just
22 relation types and 38194 entities which is order
of magnitudes less than the dataset we use for re-
lation extraction tasks.
The dimension of the relation type representations
and the RNN hidden states are d, h “ 250 and the
entity and type embeddings have m “ 50 dimen-
sions. The Path-RNN model has sigmoid units as
their activation function. However, we found rec-
tiﬁer units (ReLU) to work much better (Le et al.,
2015)3 . For the path-query experiment, the di-
mension of entity, relation embeddings and hid-
den units are set to 100 (as used by Guu et al.
(2015)). As our evaluation metric, we use the aver-
age precision (AP) to score the ranked list of entity
pairs. The MAP score is the mean AP across all
query relations. AP is a strict metric since it pe-
nalizes when an incorrect entity is ranked higher
above correct entities. Also MAP approximates
the area under the Precision Recall curve (Man-
ning et al., 2008). We use Adam (Kingma and
Ba, 2014) for optimization for all our experiments
with the default hyperparameter settings (learning
rate = 1e´3, β1 “ 0.9, β2 “ 0.999,  “ 1e´8).
Statistical signiﬁcance for scores reported in Table
3 were done with a paired-t test.

5.1 Effect of Pooling Techniques
Section 1 of Table 3 shows the effect of the various
pooling techniques presented in section 3.2. It is
encouraging to see that LogSumExp gives the best
results. This demonstrates the importance of con-
sidering information from all the paths. However,
Avg. pooling performs the worst, which shows
that it is also important to weigh the paths scores
according to their values. Figure 3 plots the train-
ing loss w.r.t gradient update step. Due to non-zero
gradient updates for all the paths, the LogSumExp

3even when compared to LSTMs (73.2 vs 72.4 in MAP)

Figure 3: Comparison of the training loss w.r.t
gradient update steps of various pooling meth-
ods. The loss of LogSumExp decreases the fastest
among all pooling methods and hence leads to
faster training.

pooling strategy leads to faster training vs. max
pooling, which has sparse gradients. This is es-
pecially relevant during the early stages of train-
ing, where the argmax path is essentially a random
guess. The scores of max and LSE pooling are sig-
niﬁcant with (p ă 0.02).

5.2 Comparison with multi-hop models
We next compare the performance of the Single-
Model with two other multi-hop models - Path-
RNN and PRA(Lao et al., 2011). Both of these ap-
proaches train an individual model for each query
relation. We also experiment with another exten-
sion of PRA that adds bigram features (PRA +
Bigram). Additionally, we run an experiment re-
placing the max-pooling of Path-RNN with Log-
SumExp. The results are shown in the second
section of Table 3.
It is not surprising to see
that the Single-Model, which leverages parame-
ter sharing improves performance. It is also en-
couraging to see that LogSumExp makes the Path-
RNN baseline stronger. The scores of Path-RNN
(with LSE) and Single-Model are signiﬁcant with
(p ă 0.005).

5.3 Effect of Incorporating Entities
Next, we provide quantitative results supporting
our claim that modeling the entities along a KB
path can improve reasoning performance. The last
section of Table 3 lists the performance gain ob-
tained by injecting information about entities. We
achieve the best performance when we represent
entities as a function of their annotated types in
Freebase (Single-Model + Types) pp ă 0.005q.

Gradient Steps#10400.511.52Training Loss0.40.50.60.70.80.911.11.2LogSumExpMaxMeanTop-kModel

Single-Model
Single-Model
Single-Model
Single-Model

PRA

PRA + Bigram

Path-RNN
Path-RNN

Single-Model
PRA + Types
Single-Model

Single-Model + Entity
Single-Model + Types

Single-Model + Entity + Types

Performance (%MAP)

68.77
55.80
68.20
70.11
64.43
64.93
65.23
68.43
70.11
64.18
70.11
71.74
73.26
72.22

Pooling

Max
Avg.
Top(k)

n/a
n/a
Max

LogSumExp

LogSumExp
LogSumExp

n/a

LogSumExp
LogSumExp
LogSumExp
LogSumExp

Table 3: The ﬁrst section shows the effectiveness of LogSumExp as the score aggregation function. The
next section compares performance with existing multi-hop approaches and the last section shows the
performance achieved using joint reasoning with entities and types.

In comparison, learning separate representations
of entities (Single-Model + Entities) gives slightly
worse performance. This is primarily because we
encounter many new entities during test time, for
which our model does not have a learned repre-
sentation. However the relatively limited number
of entity types helps us overcome the problem of
representing unseen entities. We also extend PRA
to include entity type information (PRA + Types),
but this did not yield signiﬁcant improvements.

5.4 Performance in Limited Data Regime
In constructing our dataset, we selected query re-
lations with reasonable amounts of data. However,
for many important applications we have very lim-
ited data. To simulate this common scenario, we
create a new dataset by randomly selecting 23 out
of 46 relations and removing all but 1% of the pos-
itive and negative triples previously used for train-
ing. Effectively, the difference between Path-RNN
and Single-Model is that Single-Model does mul-
titask learning, since it shares parameters for dif-
ferent target relation types. Therefore, we expect
it to outperform Path-RNN on this small dataset,
since this multitask learning provides additional
regularization. We also experiment with an exten-
sion of Single-Model where we introduce an addi-
tional task for multitask learning, where we seek to
predict annotated types for entities. Here, parame-
ters for the entity type embeddings are shared with
the Single-Model. Supervision for this task is pro-
vided by the entity type annotation in the KB. We
train with a Bayesian Personalized Ranking loss of
Rendle et al. (2009). The results are listed in Table
4. With Single-Model there is a clear jump in per-

Model

Path-RNN

Single-Model

Single-Model + MTL

Performance (%MAP)

22.06
63.33
64.81

Table 4: Model performance when trained with a
small fraction of the data.

formance as we expect. The additional multitask
training with types gives a very incremental gain.

5.5 Answering Path Queries

Guu et al. (2015) introduce a task of answering
questions formulated as path traversals in a KB.
Unlike binary fact prediction, to answer a path
query, the model needs to ﬁnd the set of correct
target entities ‘t’ that can be reached by starting
from an initial entity ‘s’ and then traversing the
path ‘p’. They model additive and multiplicative
interactions of relations in the path. It should be
noted that the compositional Trans-E and Bilinear-
diag have comparable number of parameters to our
model since they also represent relations as vec-
tors, however the Bilinear model learns a dense
square matrix for each relation and hence has a lot
more number of parameters. Hence, we compare
with Trans-E and Bilinear-diag models. Bilinear-
diag has also been shown to outperform Bilinear
models (Yang et al., 2015).

Instead of combining relations using simple ad-
ditions and multiplications, we propose to com-
bine the intermediate hidden representations hi
obtained from a RNN (via (??)) after consum-
ing relation ri at each step. Let h denote the

Horn Clause (Body)

Without Entities With Entities Universal

Y
N

location.containspx, aq ^ location.containspa, yq
(person.nationality)´1px, aq ^ place.birthpa, yq
Table 5: Body of two clauses both of which are predictive of location.containspx, yq. First fact is univer-
sally true but the truth value of the second clause depends on the value of the entities in the clause. The
model without entity parameters cannot discriminate this and outputs a lower overall conﬁdence score.

0.9149
0.7702

0.949
0.9256

Model

Comp. Bilinear Diag

Comp. Trans-E

Our Model

MQ
90.4
93.3
98.94

Table 6: Performance on path queries in WordNet.

sum of all intermediate representations hi. The
score of a triple ps, p, tq by our model is given by
s diagphqxt where diagphq represents a diagonal
xJ
matrix with vector h as its diagonal elements.

We compare to the results reported by Guu et
al. (2015) on the WordNet dataset.
It should be
noted that the dataset is fairly small with just 22
relation types and an average path length of 3.07.
More importantly, there are only few unseen paths
during test time and only one path between an en-
tity pair, suggesting that this dataset is not an ideal
test bed for compositional neural models. The re-
sults are shown in table 6. Mean Quantile(MQ) is
the fraction of incorrect entities which have been
scored lower than the correct entity. Our model
achieves a 84% reduction in error when compared
to their best model.

as Existential Quantiﬁers:

6 Qualitative Analysis
Entities
Ta-
ble 5 shows the body of two horn clauses.
Both the clauses are predictive of
the fact
location.containspx, bq. The ﬁrst clause is uni-
versally true irrespective of the entities present
in the chain (transitive property). However the
value of the second clause is only true conditional
on the instantiations of the entities. The score of
the Path-RNN model is independent of the entity
values, whereas our model outputs a different
score based on the entities in the chain. We
average the scores across entities, which are
connected through this path and for which the
relation holds in column 3 (With Entities).

For the ﬁrst clause, which is independent of en-
tities, both models predict a high score. However

Figure 4: Length distribution of top-scoring paths

for the second clause, the model without entity
information predicts a lower score because this
path is seen in both positive and negative train-
ing examples and the model cannot condition on
the entities to learn to discriminate. However our
model predicts the true relations with high conﬁ-
dence. This is a step towards the capturing exis-
tential quantiﬁcation for logical inference in vec-
tor space.
Length of Clauses: Figure 4 shows the length dis-
tribution of top scoring paths in the test set. The
distribution peaks at lengths“ t3, 4, 5u, suggest-
ing that previous approaches (Yang et al., 2015)
which restrict the length to 3 might limit perfor-
mance and generalizability.
Limitation: A major limitation of our model is
inability to handle long textual patterns because of
sparsity. Compositional approaches for modeling
text (Toutanova et al., 2015; Verga et al., 2016) are
a right step in this direction and we leave this as
future work.

7 Conclusion
This paper introduces a single high capacity RNN
model which allows chains of reasoning across
multiple relation types.
It leverages information
from the intermediate entities present in the path
between an entity pair and mitigates the problem
of unseen entities by representing them as a func-
tion of their annotated types. We also demonstrate
that pooling evidence across multiple paths im-
proves both training speed and accuracy. Finally,

Number of Paths0200040006000800010000Path Length1234567we also address the problem of reasoning about
infrequently occurring relations and show signiﬁ-
cant performance gains via multitasking.

References
[Berant et al.2011] Jonathan Berant, Ido Dagan, and Ja-
cob Goldberger. 2011. Global learning of typed en-
tailment rules. In NAACL.

[Bordes et al.2013] Antoine Bordes, Nicolas Usunier,
Alberto Garc´ıa-Dur´an, Jason Weston, and Oksana
Yakhnenko.
2013. Translating embeddings for
modeling multi-relational data. In NIPS.

[Bowman et al.2015] Samuel R. Bowman, Gabor An-
geli, Christopher Potts, and Christopher D. Man-
ning. 2015. A large annotated corpus for learning
natural language inference. In EMNLP. Association
for Computational Linguistics.

[Caruana1997] Rich Caruana. 1997. Multitask learn-

ing. Machine Learning.

[Chang et al.2014] Kai-Wei Chang, Wen tau Yih, Bis-
han Yang, and Christopher Meek. 2014. Typed ten-
sor decomposition of knowledge bases for relation
extraction. In EMNLP.

[Gardner et al.2013] Matt Gardner,

Partha Pratim
Talukdar, Bryan Kisiel, and Tom M. Mitchell.
2013. Improving learning and inference in a large
knowledge-base using latent syntactic cues.
In
EMNLP.

[Gardner et al.2014] Matt Gardner, Partha Talukdar,
Jayant Krishnamurthy, and Tom Mitchell. 2014. In-
corporating vector space similarity in random walk
inference over knowledge bases. In EMNLP.

[Grefenstette2013] Edward Grefenstette.

2013. To-
wards a formal distributional semantics: Simulating
logical calculi with tensors. Lexical and Computa-
tional Semantics.

[Guu et al.2015] K. Guu, J. Miller, and P. Liang. 2015.
In

Traversing knowledge graphs in vector space.
EMNLP.

[Kingma and Ba2014] Diederik P. Kingma and Jimmy
Ba. 2014. Adam: A method for stochastic opti-
mization. CoRR, abs/1412.6980.

[Lao et al.2011] Ni Lao, Tom Mitchell, and William W.
Cohen. 2011. Random walk inference and learn-
In EMNLP,
ing in a large scale knowledge base.
Stroudsburg, PA, USA.

[Lao et al.2012] Ni Lao, Amarnag Subramanya, Fer-
nando Pereira, and William W. Cohen. 2012. Read-
ing the web with learned syntactic-semantic infer-
ence rules. In EMNLP.

[Le et al.2015] Quoc V. Le, Navdeep Jaitly, and Geof-
frey E. Hinton. 2015. A simple way to initialize
recurrent networks of rectiﬁed linear units. CoRR.

[Manning et al.2008] Christopher D. Manning, Prab-
In-

hakar Raghavan, and Hinrich Sch¨utze. 2008.
troduction to Information Retrieval.

[Toutanova et al.2015] Kristina

Danqi
Chen, Patrick Pantel, Hoifung Poon, Pallavi Choud-
hury, and Michael Gamon. 2015. Representing text
for joint embedding of text and knowledge bases. In
EMNLP, September.

Toutanova,

[Toutanova et al.2016] Kristina Toutanova, Xi Victoria
Lin, Scott Wen tau Yih, Hoifung Poon, and Chris
Quirk. 2016. Compositional learning of embed-
dings for relation paths in knowledge bases and text.
ACL.

[Verga et al.2016] Patrick Verga, David Belanger,
Emma Strubell, Benjamin Roth,
and Andrew
McCallum. 2016. Multilingual relation extraction
using compositional universal schema.

[Yang et al.2015] Bishan Yang, Wen-tau Yih, Xiaodong
He, Jianfeng Gao, and Li Deng. 2015. Embedding
entities and relations for learning and inference in
knowledge bases. ICLR.

[Zeng et al.2016] Wenyuan Zeng, Yankai Lin, Zhiyuan
Liu, and Maosong Sun. 2016. Incorporating rela-
tion paths in neural relation extraction. CoRR.

[Min et al.2013] Bonan Min, Ralph Grishman, Li Wan,
Chang Wang, and David Gondek. 2013. Distant su-
pervision for relation extraction with an incomplete
knowledge base. In NAACL.

[Neelakantan et al.2015] Arvind Neelakantan, Ben-
jamin Roth, and Andrew McCallum.
2015.
Compositional vector space models for knowledge
base completion. In ACL, Beijing, China.

[Nickel et al.2011] Maximilian Nickel, Volker Tresp,
and Hans-Peter Kriegel. 2011. A three-way model
for collective learning on multi-relational data.
In
ICML.

[Orr et al.2013] Dave Orr, Amar Subramanya, Ev-
geniy Gabrilovich, and Michael Ringgaard. 2013.
11 billion clues in 800 million documents: A
web research corpus annotated with freebase
concepts.
http://googleresearch.
blogspot.com/2013/07/
11-billion-clues-in-800-million.
html.

[Rendle et al.2009] Steffen Rendle, Christoph Freuden-
thaler, Zeno Gantner, and Lars Schmidt-Thieme.
2009. Bpr: Bayesian personalized ranking from im-
plicit feedback. UAI ’09.

[Riedel et al.2013] Sebastian Riedel, Limin Yao, An-
drew McCallum, and Benjamin M. Marlin. 2013.
Relation extraction with matrix factorization and
universal schemas. In NAACL.

[Rockt¨aschel and Riedel2016] Tim Rockt¨aschel

and
Sebastian Riedel. 2016. Learning knowledge base
In AKBC,
inference with neural theorem provers.
NAACL.

[Roth and Yih2007] Dan Roth and Wen-tau Yih. 2007.
Global inference for entity and relation identiﬁcation
via a linear programming formulation. In In Intro-
duction to SRL.

[Schoenmackers et al.2010] Stefan

Schoenmackers,
Oren Etzioni, Daniel S. Weld, and Jesse Davis.
2010. Learning ﬁrst-order horn clauses from web
text. In EMNLP.

[Serban et al.2016] Iulian Vlad Serban, Alberto Garc´ıa-
Dur´an, Caglar Gulcehre, Sungjin Ahn, Sarath Chan-
dar, Aaron Courville, and Yoshua Bengio. 2016.
Generating factoid questions with recurrent neural
networks: The 30m factoid question-answer corpus.
ACL.

[Singh et al.2013] Sameer Singh, Sebastian Riedel,
Brian Martin, Jiaping Zheng, and Andrew McCal-
lum. 2013. Joint inference of entities, relations, and
coreference. In AKBC, CIKM.

[Socher et al.2013] Richard Socher, Danqi Chen,
Christopher D Manning, and Andrew Ng. 2013.
Reasoning with neural tensor networks for knowl-
edge base completion. In NIPS.

