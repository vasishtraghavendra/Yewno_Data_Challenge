Natural Scene Recognition Based on Superpixels and Deep Boltzmann 

Machines 

Jinfu Yang1, Jingyu Gao1*, Guanghui Wang2, Shanshan Zhang1 

1  Department  of  Control  Science  &  Engineering,  Beijing  University  of  Technology,  NO.100 
Chaoyang district, Beijing, 100124, P.R.China. 

2  Department  of  Electrical  Engineering  &  Computer  Science,  University  of  Kansas,  Lawrence,  KS 
66045-7608, USA 

* Corresponding author 

E-mail: gjy890316@126.com (JG) 

Abstract 

The Deep Boltzmann Machines (DBM) is a state-of-the-art unsupervised learning 

model,  which  has  been  successfully  applied  to  handwritten  digit  recognition  and,  as 

well as object recognition. However, the DBM is limited in scene recognition due to 

the  fact  that  natural  scene  images  are  usually  very  large.  In  this  paper,  an  efficient 

scene recognition approach is proposed based on superpixels and the DBMs. First, a 

simple  linear  iterative  clustering  (SLIC)  algorithm  is  employed  to  generate 

superpixels  of  input  images,  where  each  superpixel  is  regarded  as  an  input  of  a 

learning  model.  Then,  a  two-layer  DBM  model  is  constructed  by  stacking  two 

restricted Boltzmann machines (RBMs), and a greedy layer-wise algorithm is applied 

to train the DBM model. Finally, a softmax regression is utilized to  categorize scene 

images. The proposed technique can effectively reduce the computational complexity 

and  enhance  the  performance  for  large  natural  image  recognition.  The  approach  is 

verified  and  evaluated  by  extensive  experiments,  including  the  fifteen-scene 

categories dataset the UIUC eight-sports dataset, and the SIFT flow dataset, are used 

to  evaluate  the  proposed  method.  The  experimental  results  show  that  the  proposed 

approach outperforms other state-of-the-art methods in terms of recognition rate. 

Introduction 

Scene recognition, also called scene classification, is a necessary procedure of the 

humans’ vision system. As an important topic of computer vision, scene recognition is 

used  to  accurately  and  immediately  observe  the  surrounding  environments;  and  has 

attracted  more  and  more  attention  due  to  the  potential  wide  applications  such  as 

automatic driving and robot navigation.   

Most  early  work  in  scene  recognition  focuses  on  extracting  surface  features  to 

recognize scenes or objects. For example, color and texture are usually considered to 

be  surface  features  and  are  widely  used  to  represent  features  of  scene  images. 

Haralick  et  al.  [1]  employed  the  features  of  texture,  color  and  frequency  to  infer 

high-level  information  for  indoor  and  outdoor  categorization.  However,  the  features 

mentioned above are neither accurate nor sufficient enough to present the information 

of  images  because  they  are  unrepresentative  and  indistinguishable.  For  instance,  the 

color blue can represent either the sea or sky in scene images.   

In  recent  years,  many  researchers  have  paid  attention  to  deep-seated  features 

rather than surface features. Zheng et al.[2] proposed a mid-level image representation, 

called Hybrid-Parts, which was generated by pooling the response maps of object part 

filters, to represent compact information of input images. Jiang et al. [3] presented a 

novel  image  representation  method,  called  Randomized  Spatial  Partition  (RSP), 

which  was  characterized  by  the  randomized  partition  patterns.  The  method  makes  it 

possible  to  extract  the  most  descriptive  layout  features  for  each  category  of  scenes. 

Sadeghi  and  Tappen[4]  introduced  a  latent  pyramidal  region  (LPR)  method  .  They 

used latent SVM framework as region detectors to  capture  the  key  characteristics  of 

the  scenes.  Lin  et  al.[5]  proposed  a  joint  model  for  scene  classification,  which  used 

part appearance and important spatial pooling regions (ISPRs) to reduce the influence 

of false responses. In addition, they illustrated the promising results by combining the 

ISPR  with  an  improved  fisher  vector  (IFV)  algorithm.  However,  the  features 

mentioned above are incapable of representing the hidden information of images well, 

as the local features are always defined manually.   

Recently,  global  features  have  attracted  more  attention  from  researchers  again. 

Hinton  and  Salakhutdinov  [6]  proposed  a  multiple  restricted  Boltzman  machine, 

named deep belief networks (DBN), and a greedy layer-wise learning algorithm.  They 

introduced an effective way of initializing weights that allows deep networks to learn 

low-dimensional  information,  which  works  much  better  than  the  principal  error  of 

back  propagation  in  reducing  the  dimensionality  of  data.  Compared  to  other 

algorithms, it is an unsupervised learning method which makes it more competent for 

big data and has been succesfully applied in hand written digit recognition[7], object 

recognition[8],  and  speech  recognition[9].  In  2012,  Salakhutdinov  and  Hinton[10] 

proposed another model of deep learning, called deep Boltzman machines (DBM), by 

changing  the  structure  of  the  DBN  model;  and  the  model  enables  the  neighbouring 

layers  to  represent  each  other.  As  a  result,  the  visible  layer  can  receive 

back-propagation error of output layer and the model can fine-tune its parameters in a 

layer-by-layer way to decrease the errors.  The DBM obtains better performance than 

other  deep  learning  algorithms  in  object  recognition,  hand  written  digits  recognition 

[10][11], and multimodal containing both word and image learning[12]. 

However, when the DBM is used to extract features for natural scene recognition, 

the  issue  of  computational  complexity  must  be  considered,  since  it  requires  a  lot  of 

matrix  operations  and  hundreds  of  interactions  with  large  images  as  input  data. 

Convolution and pooling are suggested to  work with  large images[13], however,  the 

convolution  has  high  computational  complexity,  and  pooling  is  limited  by  the 

coordinates  of  pixels.  In  this  paper,  we  propose  a  new  natural  scene  recognition 

method based on superpixels and the DBM. First, large-sized natural scene images are 

preprocessed  by  the  SLIC  algorithm  to  reduce  their  sizes.  Superpixels  are  generated 

through grouping the pixels into atomic regions  where the pixels are assigned to the 

same labels defined by the distance  between  the  cluster  center  and  each  pixel  in  the 

given  region.  Then,  a  two-layer  DBM  model  is  constructed  by  stacking  two  RBMs 

(see  Fig.  3(a)),  and  the  superpixels  are  regarded  as  the  input  data  to  train  the  DBM 

model in a layer-by-layer way. After training the first  two layers  of  the  DBM  model 

(i.e.,  the  first  RBM),  the  parameters  are  frozen  and  the  second  RBM  is  trained  by 

using  a  greedy  layer-wise  algorithm,  with  the  output  of  the  first  RBM  used  as  the 

input of the second RBM. Other layers of the DBM model are trained in the same way. 

Finally, a softmax classifier is employed to classify  the extracted features.  The main 

contributions of this paper are as follows: 

(1) We propose a novel scene recognition method that combines  the superpixels and 

the DBM for categorizing large-sized natural images. 

(2) The superpixels-based preprocessing  strategy can obtain  better  performance  than 

the convolution and pooling for the DBM in recognizing natural scene images.   

(3) The  proposed  method  performs  better  than  other  counterparts  in  terms  of 

recognition rate. 

The remainder of this paper is organized as follows. In section 2, the structure of the 

restricted Boltzmann machine and its learning procedure is introduced. Section 3 presents 

the  architecture  of  the  DBM and  the  greedy  layer-wise  algorithm  for  learning  the  DBM 

model.  Section  4  describes  the  process  of  image  preprocessing  with  the  SLIC.  The 

proposed scene recognition method with the softmax regression is elaborated in Section 5. 

The  performance  of  the  proposed  method  is  evaluated  and  discussed  in  Section  6  using 

three datasets. Finally, the paper is concluded in Section 7. 

Background on RBM and Model Learning 

In this section, we introduce the RBM, which is the basis of the DBM. Since the 

DBM is a stacked RBMs, the training process of each DBM layer is the same as that 

of the RBM.   

Restricted Boltzmann Machine 

The RBM is the variant of Boltzmann machine[14], and it consists of visible units 

  and hidden units 

. As shown in Fig. 1, the units in neighboring   

0,1pv0,1ph 

 
Fig.  1  Interaction  graph  of  an  RBM. 
represents  the  weight  matrix  between  the  visible  units  and  the  hidden  units,  where  the  number  of 
rows and columns of 

equals to the number of the visible units and hidden units. 

represents visible units and 

denotes hidden units. 

     

layers are connected by the weights, but the units in the same layer  do not link with 

each other in order to reduce the computational redundancy. 

The  probability  parameter  of  the  RBM  is 

,  where 

  represents  the 

weight  matrix  between  the  visible  layer 

  and  the  hidden  layer 

;  and 

and 

 

denote  hidden  and  visible  unit  biases,  respectively.  The  joint  energy  function  of  an 

RBM is defined as 

 

where  and   are respectively the iterations of the visible and hidden units. From 

equation  (1),  a  good  model  of  data  with  the  parameter 

  is  interpreted  as  a  model 

that  has  high  energy  in  regions  of  low  data  density  and  low  energy  elsewhere  [15]. 

The matrix 

of connection weights between units is symmetric.   

According  to  the  joint  energy

,  an  RBM  associates  to  each  state 

and 

, and the probability is given by 

where 

  is  the  natural  exponential  function,  and 

  is  a  normalization 

constant given by 

 

vWhvhWWW,b,cWvhbc,,,;  1                               iijjiijjijijEvWhbvchvhθijθWEv,h;θ0,1pv0,1ph1exp                                       2pEZhv,hv,h,θθexp()ZθFrom  the  above  equations,  the  conditional  probability  of  each  unit  in  one  layer 

being activated given the units in the other layer is defined as 

 

 

 

where

  represents the sigmoid function as 

. 

Model learning 

Maximum  likelihood  estimation  (MLE)  is  a  typical  approach  to  learning  the 

parameters of the RBM. The gradient ascent of the log-likelihood with respect to 

  is 

 

where 

  is given by equation (1), and 

represents the expectation of all 

visible  vectors 

  in  regard  to  the  data  distribution, 

denotes  the  model 

distribution  defined  by  equation  (2).  Unfortunately,  computing  expectation  involves 

an  exponential  number  of  terms,  which  makes  it  difficult.  Therefore,  the  contrastive 

divergence (CD) [16] is commonly adapted to learn  the  RBM model  by  maximizing 

the likelihood. Based on the CD algorithm, the parameters are updated as below. 

 

where 

  is the learning rate for each parameter,

takes the value from the 

exp                                            3ZEvhθv,h,θ1                     4jjijijijpphphWvchvvv1()                     5iiijjiijppvpvWhbvhhh11xxeθmod()()                            6dataelEELv;θv;θθθθθ()Ev;θdatavmodel0010203                                                                                                 (7)          nnijijijijniiiinjjjjWWvhvhbbvvcchh1,2,3ii0v 

 

Fig.  2  The  procedure  of  Gibbs  sampling.  Given 

, 

is computed. Given 

, 

is 

computed. Repeat this procedure 

  times, and obtain the values of 

  and 

. 

 
observed  data  distribution, 

is  defined  by  equation  (4), 

  is  acquired  from  the 

sampled data by 

-step Gibbs sampling, and 

  is obtained from equation (4) based 

on 

.   

We  obtain 

and 

  using  the  alternative  Gibbs  sampling,  as  shown  in  Fig.  2. 

During  CD  learning,  Gibbs  sampling  [17]  is  initialized  at  each  variable,  and  it  only 

requires  a  few  steps  to  approximate  the  model  distribution  [10].  To  introduce  the 

procedure  of  Gibbs  sampling,  we  define 

,  where 

denotes  the  n-th    Gibbs 

sampling and 

  denotes the number of units. First, for all hidden units  ，compute 

  where 

  stands  for  the  original  visible  units; 

  equals  to 

.Then,  compute 

and  let 

  equals  to 

,  where 

stands for the reconstructed data of the input data. Next, compute 

  and 

the value of 

is replaced by 

where 

stands for the reconstruction data 

of 

. Repeat the above steps n times to obtain 

  and 

. 

Deep Boltzmann Machines 

A DBM is stacked by the RBMs. Unlike the DBN model [7], the DBM combines 

bottom-up and top-down passes and has better generative property. 

0v0h1v1hnv...nhWWWWvphvhpvhnnvnh0hnvnnhnvnvnhnjhnj0ih00iphv0v00,1ih00iphv011jpvh1v011jpvh1v11 1iphv1h11 1iphv1h0hnvnh 

Fig.  3 The DBM structure and its learning procedure. (a) the structure of a two layer DBM where 
each layer is an RBM, 
  represent the first hidden layer and the 

  stands for visible units, 

  and 

second  hidden  layer  respectively. 

  denotes  the  weight  matrix  between  the  visible  layer  and  the 

first  hidden  layer. 
hidden layer. (b) the learning procedure of the DBM.   
 

stands  for  the  weight  matrix  between  the  first  hidden  layer  and  the  second 

The  approximate  inference  procedure  of 

for  the  DBM  includes  an  initial 

bottom-up pass and a top-down feedback to make the DBM receive back-propagation 

error from the output layer. As shown in Fig.  3, the DBM model is stacked by RBMs 

and  it  has  the  potential  of  learning  hidden  relationships  among  hidden  units  even 

though  they  become  increasingly  complicated.  In  addition,  the  DBM  model  can 

extract features from a large number of unlabeled input data, and then, be fine-tuned 

by  using  a  few  labeled  data.  Fig.  3(a)  illustrates  an  example  of  a  two-layer  DBM 

model. The energy of the state 

is defined as 

 

where 

  are the parameters of the model, and the biases of each layer 

are ignored here. 

  represents the connection matrix between the visible layer and 

the hidden layer, and 

denotes the connection matrix between the first hidden layer 

and the second hidden layer.  The probability over the visible units 

  assigned by the 

v1W1h2Wv1W2W1h2h2hv1W1h2W2hRBMRBM(a) structure of a two layer DBM(b) learning procedure of a two layer DBMv1h2h1W2WW12v,h,h                                    8ETT1211122v,h,h;θ-vWh-hWh    12θ=W,W1W2Wvmodel is: 

The conditional distributions between the visible and the hidden units are: 

   

 

 

 

Concerning  the  MLE  learning,  we  can  still  adapt  the  learning  procedure  of 

standard Boltzmann machines, but it runs rather slowly, especially when the amount 

of  hidden  layers  is  large.  Therefore,  the  greedy  layer-wise  algorithm  [7]  is  a  better 

way  to  learn  the  DBM  model,  which  can  quickly  initialize  the  model  parameters  to 

suited values. 

Learning with Greedy Layer-wise 

Greedy layer-wise, as the name implies, is an unsupervised layer-by-layer learning 

algorithm.  As  shown  in  Fig.  3(a), two  adjacent  layers  are  regarded  as  an  RBM,  and 

each layer is trained in the way as described in section 2.2.  The procedure of greedy 

layer-wise  learning  is:  first,  train  the  first  RBM  which  consists  of  a  visible  layer 

 

and  the  first  hidden  layer 

.  Then,  compute 

(see  equation  (4))  using  the 

trained 

  and substitute for 

. Next, train the second RBM as described in section 

2.2,  regarding  the  updated 

and 

  as  the  visible  layer  and  the  hidden  layer, 

1exp                                 9pEZ12hh12v;θv,h,h;θθ11221                                 10jijijmjimphWvWh2v,h221      1                                               11mimiiphWh1h11  1                                                 12iijjjpvWh1hv1hp1hv1W1h1h2hrespectively. Other layers of the DBM model can also be trained in the same way as 

mentioned above. 

As shown in Fig.  3(b), when training the DBM model, the value of 

  is not only 

related  to 

but  also  to 

.  Thus, 

  is  calculated  using 

bottom-up  and 

top-down, which combines both top-down and bottom-up influence. In order to 

conveniently compute this, we adapt the approach of doubling the number of units of 

visible layers and top hidden layers, and tie the visible-to-hidden weights of the first 

layer RBM and the top-level RBM to two copies, as described in [10]. 

The conditional distributions of the hidden and visible states take the form 

 

 

where  the  CD  algorithm  and  Gibbs  sampling,  as  described  in  section  2.2,  are 

employed to update 

. 

For the second RBM, the first hidden layer 

is regarded as the visible layer and 

its value equals to

; and 

is regarded as the hidden layer. Since 

is also 

the  top  hidden  layer  in  the  two  layer  DBM,  the  rule  of  doubling  units  and  weights 

mentioned  above  is  also  applied  to 

.  Thus,  the  conditional  distributions  for  the 

second RBM are defined as 

 

1h1W2W1h21W22W1111                                      13jijiijiiiphWvWvv11                                            14iijjjpvWh1=1hijW1hp11h;W2h2h2h221221                               15jjmmjmmmmphWhWh2h 

After training the adjacent stacked RBMs, the value of 

  would be recomputed 

using  the  neighboring  RBMs  with  the  trained 

  and 

.  So 

is  redefined  by 

and 

as 

where 

and 

  are the same as in equations (14) and (16) respectively.   

 

Preprocessing with the SLIC   

As shown in Fig.  3, one unit of the visual layer in  a DBM model represents one 

pixel.  If  the  input  image  is  large,  the  computational  complexity  of  learning  a  DBM 

model  will  increase  rapidly.  Therefore,  it  is  necessary  to  perform  an  image 

preprocessing to reduce feature dimensionality. 

Generally speaking, convolution and pooling are two effective ways to reduce the 

image size [13]. Using the pooling algorithm to resize a large natural image, however, 

will  lose  much  more  information;  and  the  pooling  algorithm  is  limited  by  the 

coordinate of pixels. In addition, utilizing a convolution algorithm for preprocessing 

large  images  is  a  time-consuming  process.  So  it  is  of  great  importance  to  find  a 

suitable  preprocessing  approach  for  large  image  recognition.  Superpixels  have 

become  a  popular  preprocessing  method  in  computer  vision  applications,  such  as 

segmentation and object localization. 

2211                                         16mjmjjphWh1h1h1W2W1hv2h11221                            17jijijmmimphWvWh2v,hiv2mh 

Fig. 4 Illustration of searching region for a new cluster center. Yellow arrows are the searching 

region  of  standard  superpixels  in  the  whole  image.  Red  arrows  represent  SLIC  searching  region 

which becomes

. 

Superpixels 

A superpixel is a meaningful atomic region combining similar pixels according to 

the  texture,  color,  location,  etc.  superpixel  can  reduce  the  image  redundancy  and 

greatly decrease the complexity of subsequent image processing tasks [18]. In recent 

years, many superpixel algorithms have been proposed for image segmentation [19].   

In  general,  superpixel  algorithms  can  be  classified  into  two  categories: 

graph-based  methods  and  gradient  ascent  methods.  Graph-based  approaches  treat 

each  pixel  as  a  node  and  the  relationship  between  neighboring  nodes  as  an  edge, 

similar  to  graph  models.  The  edges  are  computed  by  minimizing  a  cost  function 

defined  by  prior  knowledge.  Gradient  ascent  methods  start  from  a  random  initial 

gathering of pixels, and then iteratively compute the clusters until convergence. 

Simple Linear Iterative Clustering 

Simple linear iterative clustering (SLIC) is proposed by  Achanta et al.[18], which 

..22SSis  faster  and  more  memory  efficient  than  other  superpixel  methods.  Since  there  is 

onlyone  parameter 

,  the  desired  number  of  superpixels,  the  SLIC  is  easy  to 

implement and understand. Firstly, a cluster center  , 

is randomly chosen 

in an 

  region, where 

is the region size and 

  is the total number of 

pixels  in  an  image.  Find  the  lowest  gradient  pixel  to  replace 

in  the 

 

neighborhood. Then, in order to decrease computational complexity, a local k-means 

algorithm is employed to assign each pixel around 

neighboring 

  region to 

the  nearest  cluster  center  as  shown  in  Fig.  4.  The  cluster  center 

  and  the  pixel 

 

label 

are  updated  according  to  the  distance 

  between 

and  pixel 

. 

Since color and position in space are the most obvious information in an RGB image, 

the distance 

  is defined by combining color distance with space distance in this 

paper.  The  distance  between  two  colors  is  a  metric  of  interest  in  color  science  [20]. 

For  the  SLIC,  CIE76  [21],  the  first  color  distance  formula  is  selected  as  the  color 

distance  that  relates  a  measure  to  a  known  Lab  (label)  value,  and  is  defined  as  the 

distance between two colors is a metric of interest in color science [20]. For the SLIC, 

CIE76  [21],  the  first  color  distance  formula  is  selected  as  the  color  distance  that 

relates a measure to a known Lab (label) value, and is defined as 

where  l  stands  for  luminance.  The  parameters 

  and 

respectively  represent 

green  or  red  and  blue  or  yellow.  The  Euclidean  distance  is  defined  as  the  spatial 

distance 

 

k1,2,...,kKSSSNKNkC33kC22SSkCilabiDikCiDi222                                  18cjijijidllaabbab 

Fig.  5  Illustration of natural scene recognition based  on the  DBM  model.  The DBM is used to 

extract  features  after  preprocessing  of  superpixels,  while  the  softmax  classifier  is  employed  to 

classify extracted features. 

Thus, the distance D is defined as: 

 

 

where 

  and 

is  determined  by  the  signification  of  the  color 

distance between two clusters. In this paper, we fix 

to a constant value m. After 

simplification, 

  is written as 

 

Finally,  the 

  norm  is  adopted  to  represent  the  residual  error 

  between  the 

new  cluster  center  and  the  previous  one. We  then  iteratively  repeat  the  update  steps 

v1W1h2W2hDBMSoftmax classifier............superpixel22                                         19sjijidxxyy22                                               20cscsddDNNSNSNKcNcND22                                             21scdDdmS1LEuntil 

  converges. In order to enforce connectivity, the disjoint pixels are reassigned 

to its nearby superpixels.   

Dimensional Reduction by the SLIC 

The  SLIC  is  widely  used  in  image  segmentation  due  to  its  superiority  in 

computational  speed.  This  algorithm  substantially  integrates  the  pixels  based  on  the 

similarity  in  location  and  color.  This  idea  can  also  be  used  to  reduce  image 

dimensions.  For  example,  after  generating  superpixels,  each  superpixel  can  be 

regarded as a new pixel in the image, which can effectively reduce image dimensions. 

Different  to  convolution  and  pooling  methods  that  only  rely  on  pixel  location,  the 

SLIC  combines  location  and  color  information  to  enhance  the  performance  of 

dimensional reduction, which is helpful for subsequent image processing tasks. 

Scene Recognition with Softmax Regression 

In order to perform scene recognition, softmax regression was used to classify the 

scene images in our experiments. The architecture of the proposed model for natural 

scene  images  is  shown  in  Fig.  5.  Softmax  regression  is  a  variant  of  the  logistic 

regression model which is only applied to binary classification. In  this paper, we are 

interested  in  multi-class  classification. When  setting  the  softmax  classifier,  the  label 

can  take  on  different  values  rather  than  only  two.  Thus,  we  have  the  training  set 

  of 

    labeled examples and 

. To obtain the 

probability  of  the  class  labels  from  the 

  possible  values  given  a  test  input 

,  the 

E11,,...,,mmxyxym1,2,3,...,iykkxhypothesis  is  estimated  by  the  probability

  for  each  value  of 

. 

Therefore, the hypothesis will yield a 

-dimensional vector (whose elements sum to 

1)  giving 

  estimated  probabilities.  Specifically,  the  hypothesis  function 

  takes 

the following form. 

 

where  θ  is  the  parameter  of  the  softmax  regression  model;  and 

  is  a 

normalization term for the distribution.   

The parameter θ is learned in order to minimize the cost function. In equation (23), 

  is 

the 

indicator 

function, 

that 

is 

, 

and   

. For example, 

evaluates to 1; and 

evaluates 

to 0. So the cost function is written as 

 

where  θ  is  initialized  as  any  random  number.  Note  that  in  softmax  regression, 

  is known as 

pyjx1,2,...,jkkkxh1()()()2()()31()()1;2;1                         23;;TiiTiiiTiiTjkjiiTkxipyxexipyxehxxipyxxieexipykxe21Tjkjxie11= 1 atruestatement0(cid:160) 1=afalsestatement11+1=211+1=4111011log1log1      1log1                              23miiiiimiiiijJyhxyhxmyjpyxm；();iipykxθ 

There  is  no  closed-form  approach  to  solve  for  the  minimum  of 

,  and  thus, 

some 

iterative 

optimization 

algorithm, 

such 

as 

gradient 

descent 

or 

L-BFGS(Limited-memory  BFGS),  can  be  adopted.  Taking  derivative  of  the  cost 

function (24), we have 

 

where, 

  is a vector whose l-th element is the partial derivative of 

  with 

respect  to  the  l-th  element  of 

.  Then,  in  each  iterations, 

can  be  updated  by 

, with 

.   

When implementing softmax regression, we usually use a modified version of the 

cost  function  by  adding  a  decay  term  as  below.  The  weight  decay  term  avoids  the 

solution of large values of the parameters.   

 

The implementation of the proposed algorithm based on superpixels and the DBM 

for natural scene images is summarized as follows. 

(1) Generate superpixels using SLIC. 

a) 

  Randomly  select  an  initial  cluster  centers  in  each 

  region,  and 

find the lowest gradient pixels to replace the cluster centers in a 

  neighbor 

region; 

1;                                     24TxijiiTxikllepyjxeθJ1111                      25miiiijiJxyjpyxm；jJjjjjjJ1,...,jk12101011log1            262mkniiiijijijJyjpyxmθ；SS33b) 

  For each cluster center, calculate the distance 

  between the cluster 

center  and  each  pixel  in  the 

  neighbor  region,  and  update  the  cluster 

centers ; 

c) 

  Calculate  the  residual  error 

  using 

  norm  distance,  repeat  step 

b) until 

; 

(2) Take the superpixels obtained in (1) as the input data of the visible units, train 

the DBM model using the CD algorithm and the Gibbs sampling. 

a) 

  Given  the  visible  units

,  calculate 

,  and    replace 

  by 

the value of 

;   

b) 

  Compute 

, and set the reconstructed value 

  as 

; 

c) 

  Use  the  Gibbs  sampling  to  get 

and 

;  and  update  the  weight 

matrix 

  using the CD algorithm; 

d) 

  Repeat  steps  a)  to  c)  iteratively  until  convergence  or  reaching  the 

maximum number of iterations; 

e) 

  Repeat steps a) to d) to compute the second layer and learn the weight 

matrix

; 

f) 

  Rconstruct 

  using 

and 

according to equation (17); 

(3) Repeat step (2) to train other RBMs in the DBM. 

(4)  Employ  softmax  regression  to  categorize  scene  images  using  the  extracted 

features. 

D22SSE1L thredEshol1vp111hv1hp111hvp211vh2vp211vhnv1nh1W2W1h1W2W 

Fig.  6 The preprocessed images with different  sizes  pooling and SLIC respectively. The top row 
images are preprocessed using pooling and the bottom images are preprocessed by SLIC. The papers 
on  the  wall  in  the  bottom  row  are  more  distinct  than  the  ones  in  the  top  row,  which  breaks  the 
specific shape of the computational region. 

Experiments and Results 

We select three different  public scene datasets to evaluate the proposed approach. 

In  this  paper,  all  experiments  were  performed  on  a  Sony  PC  with  an  Intel  Core  i3 

CPU 350 @2.27GHz, and 6GB of random access memory. The experimental  results 

are reported as below. 

Fifteen-Scene Dataset 

The fifteen-Scene dataset [22] includes 4485 images of fifteen-scene categories 

describing different indoor and outdoor scenes. The size of the images is roughly 

  pixels. In this paper, we respectively used the SLIC and the pooling 

approach to preprocess images. First, the all images are resized to 

  pixels. 

Then, the SLIC and pooling were respectively applied to reduce the image sizes to 

  pixels, 

  pixels, and 

  pixels. The results are shown in Fig. 6, 

from which we can see that the SLIC can catch more boundary information of the   

Original images20x2025x2540x4050x50PoolingSLIC200300200200202025254040 

Fig.  7 The preprocessing results of scene images using the pooling and the SLIC, respectively. 
The original image sizes are all 200x200 pixels and the preprocessed image sizes are all 40x40 pixels. 
The SLIC results are more distinct, and the curvature of objects was clearly visible, especially in the 
third and fourth columns. 

objects. In Fig.  6, the papers on the wall can be distinguished in images ranging from 

  pixels  to 

  pixels  preprocessed  by  the  SLIC,  while  they  can  only  be 

identified  in  the 

  pixel  images  using  the  pooling  algorithm.  We  also 

preprocessed different categories of scene images, both indoor and outdoor, using the 

SLIC and pooling. Some example images and the corresponding preprocessed results 

of 

  pixels are shown in Fig.  7. It can be seen that the results of the SLIC are 

more  distinct  and  the  curvatures  of  objects  are  clearly  visible,  especially  in  the 

third-column and the forth-column.   

Table 1. Recognition rate of different sizes of preprocessed images   

Image   

Size 

Preprocessing   
Method 

Pooling 

SLIC 

20x20 pixels 

25x25 pixels 

40x40 pixels 

50x50 pixels 

81.3% 

80.9% 

84.7% 

89.7% 

87.2% 

93.2% 

88.4% 

93.8% 

Initial Images SLIC Results Pooling Results 2525505050504040Table 2. Recognition rate over 15-scene dataset 

Method 

Recognition Rate(%) 

GIST-color[26] 

RBow[27] 

Classmes[28] 

Object Bank[29] 

SP[16] 

SPMSM[30] 

LCSR[31] 

SP-pLSA[32] 

CENTRIST[33] 

HIK[34] 

VC+VQ[35] 

LMLF[36] 

LPR[4] 

RSP[3] 

LScSPM[37] 

ISPR+IFV[5] 

Our Approach 

69.5 

78.60 

80.60 

80.90 

81.40 

82.30 

82.67 

83.70 

83.88 

84.12 

85.40 

85.60 

85.81 

88.10 

89.75 

91.06 

93.50 

In the experiments, we selected 200 images per class for training and 20 images 

per class for testing. We constructed the DBM stacked by two RBMs to extract image 

features. Since the input images are preprocessed into different sizes, we constructed   

different structural DBMs for scene recognition. For the images of 

  pixels and 

  pixels, we built a DBM with 300 units of the first hidden layer and 200 units 

of  the  second  hidden  layer.  For  larger  input  images  of 

  pixels  and 

 

pixels, we constructed a DBM with 1000 units in the first hidden layer and 500 units   

2020252540405050 

Fig.  8  Some  reconstruction  images  using  the  UIUC  8-sports  dataset.  The  top  row  shows  the 
original images preprocessed by the SLIC; and the bottom row shows the reconstructed images. The 
reconstructed images contain most of the information from the original images. 
 

in  the  second  hidden  layer  to  extract  features.  Table.1  shows  the  recognition  results 

using  different  sizes  of  preprocessed  images  as  the  input  data  for  the  fifteen-scene 

dataset.  As  demonstrated  in  Table.1,  the  recognition  rate  is  improved  with  the 

increase of the input image size; in every cases, the results of the SLIC are better than   

those from the pooling method. For example, the recognition rate of the input images 

of 

  pixels  is  the  highest  in  our  experimental  results.  However,  it  is  worth 

noting that the computing cost will increase dramatically  with  the  increase  of  image 

sizes. When the input image size is 

pixels, the real computation time is 34775 

seconds  for  recognizing  the  fifteen-scene  dataset,  while  the  consuming  time  is  4277 

seconds when the input image size is 

  pixels.     

  Table.2 shows the recognition rates of our approach compared to other methods, 

where  the  DBM  model  was  built  with  1000  units  for  the  first  hidden  layer  and  500 

units for the second hidden layer for the input images of 

  pixels.    It is evident 

that  the  proposed  approach  outperforms  all  other  counterparts,  including  the  most 

recent technique [5] published at CVPR 2014, in terms of accuracy for natural scene 

Original imagesReconstructed images5050505040404040image recognition. 

UIUC 8-Sports Dataset 

The  UIUC  8-sports  dataset  was  built  by  Li-Jia  and  Fei-Fei  [23].  It  contains 

eightdifferent  sport  scenes:  rowing  badminton,  polo,  bocce,  snowboarding,  croquet, 

sailing,  and  rock  climbing.  The  image  sizes  are  around 

  pixels.  In  our 

experiments,  we  first  resized  all  images  to 

  pixels;  and  then,  their 

dimensionality is further reduced to 

  pixels using the SLIC. We selected 100   

Table 3. Recognition rate over UIUC8-sports dataset 

Method 

GIST-color[26] 

RBow[27] 

Classmes[28] 

Object Bank[29] 

SP[16] 

SPMSM[30] 

LCSR[31] 

SP-pLSA[32] 

CENTRIST[33] 

HIK[34] 

VC+VQ[35] 

LMLF[36] 

LPR[4] 

RSP[3] 

LScSPM[37] 

ISPR+IFV[5] 

Our Approach 

Recognition 

Rate(%) 

70.70 

71.70 

73.4 

76.3 

79.52 

79.6 

81.80 

83.00 

84.20 

85.2 

85.3 

86.25 

88.37 

88.40 

90.92 

92.31 

92.50 

10008006006005050images  per  class  as  the  training  set  and  20  images  per  class  as  the  testing  set.  The 

structure of the DBM contains 1000 units for the first hidden layer and 500 units for 

the second hidden layer. Some original images sampled from the training set and their 

reconstructed images are showed in Fig.  8. We can see that the reconstructed images 

using the extracted features contain most of the information from the original images. 

After  extracting  the  features,  the  softmax  regression  is  applied  to  categorize 

scenes over the UIUC 8-sports dataset. As shown in  Table.3, the  recognition  rate  of 

the proposed method is higher than all state-of-the-art approaches. 

SIFT Flow Dataset 

The  SIFT  Flow  dataset  [24]  consists  of  2,688  images  and  is  split  into  2,488 

training images and 200 test images. The dataset was employed in scene labeling and 

scene  parsing[25].  The  size  of  all  images  is  256x256  pixels.  Cle´ment  Farabet  [25] 

employed  the  convolutional  network  (ConvNet),  which  is  another  popular  model  of 

deep  learning,  to  recognize  scenes  on  the  SIFT  Flow  dataset.  In  this  paper,  we  also 

test the performance of our method using this dataset. First, we reduced the size of the 

images to 

  pixels. Then, we trained a DBM with 1024 visible units, 500 units 

of  the  first  hidden  layer,  and  200  units  of  the  second  hidden  layer.  Finally,  the 

extracted features were classified by using the softmax classifier. The recognition rate 

for the SIFT Flow dataset achieves 80.1%. 

Discussions 

Deep  learning  models,  such  as  the  DBN  and  the  DBM,  have  attracted  more  and 

3232more attention, and been successfully applied to the recognition tasks. However, since 

the  sizes  of  natural  images  are  always  very  large,  the  problem  of  computational 

complexity must be considered when designing the DBM model for scene recognition. 

In this paper, we presented a scene recognition method that combines superpixels and 

the  DBM  model.  Since  the  SLIC  can  generate  superpixels  efficiently,  our  method 

performs  better  than  the  pooling  algorithm  for  dimensionality  reduction  of  natural 

images. The experimental results on the fifteen scene dataset, UIUC 8-sports dataset, 

and  the  SIFT  Flow  dataset  show  that  the  proposed  method  can  obtain  the  best 

performance  than  other  counterparts  in  terms  of  recognition  rate.  During  the 

experiments, however, we also find that the structure of the constructed DBM model 

will influence the recognition results. For input images with 

  pixels, the DBM 

with  400  units  of  the  first  hidden  layer  and  200  units  of  the  second  hidden  layer 

obtained a recognition rate of 73.7%, as a contrast, the DBM with 1000 units of  the 

first hidden layer and 500 units of the second hidden layer achieved a recognition rate 

93.2%.  In  addition,  using  the  DBM  model  to  extract  features  is  computational 

intensive  when  the  input  data  size  becomes  large.  For  example,  when  we  use  a 

two-layer  DBM with  1000  first  hidden  units  and  500  second  hidden  units  to  extract 

features for the fifteen-scene dataset, the real computation time decreases from 34775 

to 4277 seconds if the input images are decreased from 

  to 

  pixels. 

Conclusions 

In  this  paper, we  have  presented  a  new  approach  for  scene  recognition  based  on 

404050504040superpixels and the DBM model. First, we used the SLIC to preprocess large natural 

images,  which  can  effectively  reduce  the  computational  complexity  for  subsequent 

image processing tasks. Compared to the pooling algorithm, the SLIC preprocessing 

can  preserve  more  information  found  in  the  images,  which  is  critical  for  scene 

recognition.  Then,  we  constructed  a  two-layer  DBM  model  to  extract  features  in  an 

unsupervised  manner  and  utilized  the  softmax  regression  to  classify  the  scenes.  The 

experimental  results  over  the  fifteen-scene  dataset,  the  UIUC  8-Sports  Dataset,  and 

the  SIFT  Flow  dataset  demonstrate  that  the  proposed  method  performs  better  than 

other counterparts in terms of scene recognition accuracy. In the future study, we will 

further investigate how to construct a more effective structure of the DBM model for 

practical applications. 

Acknowledgement 

This  work  is  partly  supported  by  the  National  Natural  Science  Foundation  of 

China  under  grant  Nos.  61201362  and  61273282,  the  Beijing  Natural  Science 

Foundation  under  grant  No.7132021,  and  the  Scientific  Research  Project  of  Beijing 

Educational Committee under grant no. KM201410005005. 

References 

[1]  R. M. Haralick, K. Shanmugam and I. Dinstein. Textural features for image classification. IEEE 
Transactions on Systems, Man, and Cybernetics.1973 Nov; SMC-3( 6): 610-621. 

[2]  Y.  Zheng,  Y.  Jiang,  and  X.  Xue.  Learning  Hybrid  Part  Filters  for  Scene  Recognition.  ECCV. 
2012; 5: 172-185   

[3] Y. Jiang, J. Yuan, and G. Yu. Randomized spatial partition for scene recognition. ECCV.2012; 2: 
730-743. 

[4]  F. Sadeghi and M. F. Tappen. Latent pyramidal regions for recognizing scenes. ECCV. 2012; 5: 
228-241 

[5]  D.  Lin,  C.  Lu,  R.  Liao,  and  J.  Jia.  Learning  Important  Spatial  Pooling  Regions  for  Scene 
Classification. CVPR 2014: 3726-3733. 

[6]  G. E. Hinton and R. Salakhutdinov. Reducing the dimensionality of data with neural networks. 
Science.2006 July 28; 313( 5786): 504 - 507. 

[7]  G.  E.  Hinton,  S.  Osindero  and  Y.  Teh.  A  fast  learning  algorithm  for  deep  belief  nets.  Neural 
Comput.2006; 18: 1527–1554. 

[8]  V.  Nair  and  G.  E.  Hinton.  3D  Object  Recognition  with  Deep  Belief  Nets.  NIPS  2009: 
1339-1447. 

[9]  A. Mohamed, G. Dahl and G. E. Hinton. Deep Belief Networks for phone recognition. NIPS 22 
workshop on deep learning for speech recognition. 2009 Dec. 

[10]   R.  Salakhutdinov  and  G.  E.  Hinton.  An  efficient  learning  procedure  for  deep  Boltzmann 
machines. Neural Comput. 2012 Aug; 24( 8): 1967–2006. 

[11]   R. Salakhutdinov and G. E. Hinton. A Better Way to Pretrain Deep Boltzmann Machines. NIPS 
2012: 2456-2464. 

[12]    N. Srivastava and R. Salakhutdinov. Multimodal Learning with Deep Boltzmann Machines. 
NIPS 2012: 2231-2239 

[13]    UFLDL Tutorial. [Internet]. Working with Large Images . Available: 
http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial.. 

[14]   G.  E.  Hinton  and  Terrence  J.  Sejnowski.  Parallel  distributed  processing:  explorations  in  the 
microstructure of cognition. MIT Press. 1986; l: 282–31. 

[15]    K.-R.  M.  Grégoire  Montavon,  “Deep  Boltzmann  machines  and  the  centering  trick,”  Lect. 
Notes  Comput.  Sci.  (including  Subser.  Lect.  Notes  Artif.  Intell.  Lect.  Notes  Bioinformatics),  vol. 
7700 LECTU, pp. 621–637, 2012. 

[16]  G.  E.  Hinton.  Training  products  of  experts  by  minimizing  contrastive  divergence.    Neural 
Computation. 2002; 14(8): 1771-1800. 

[17]   Y Bengio. Learning Deep Architectures for AI.    Foundations and Trends in Machine Learning. 
2009; 2(1): 1-127. 

[18]   R.  Achanta,  A.  Shaji,  K.  Smith,  A.  Lucchi,  P.  Fua,  and  S.  Süsstrunk.  SLIC  superpixels 
compared  to  state-of-the-art  superpixel  methods.    IEEE  Trans.  Pattern  Anal.  Mach.  Intell. 
2012;34(11): 2274-2282. 

[19]   X. Ren and J. Malik. Learning a classification model for segmentation. ICCV 2003: 10-17. 

[20]    Color Difference. [Internet]. CIE 76. 
Available:http://en.wikipedia.org/wiki/Color_difference.   

[21]   A.  R.  Robertson,  “Historical  development  of  CIE  recommended  color  difference  equations,” 
Color Research & Application.1990; 15 (3): 167–170.   

[22]   S. Lazebnik, , C. Schmid and J. Ponce. Beyond Bags of Features: Spatial Pyramid Matching for 
Recognizing Natural Scene Categories.   CVPR. 2006; 2: 2169-2178 

[23] L.-J. Li and F.-F. Li. What, where and who? Classifying event by scene and object recognition. 
ICCV. 2007:1-8. 

[24] C. Liu, J. Yuen and A. Torralba:, “Nonparametric Scene Parsing:Label Transfer via Dense Scene 
Alignment. CVPR. 2009: 1972-1979. 

[25] Clément Farabet, C. Couprie, L. Najman and Y. LeCun. Learning hierarchical features for scene 
labeling. IEEE Trans. Pattern Anal. Mach. Intell. 2013; 35(8): 1915-1929. 

[26]  A.  Oliva  and  A.  Torralba.  Modeling  the  shape  of  the  scene:  A  holistic  representation  of  the 
spatial envelope. International Journal of Computer Vision.2001; 42(3): 145-175. 

[27] S. N. Parizi, J. G. Oberlin, and P. F. Felzenszwalb. Reconfigurable models for scene recognition. 
CVPR. 2012: 2775-2782. 

[28]  L.  Torresani,  M.  Szummer,  and  A.  Fitzgibbon.  Efficient  object  category  recognition  using 
classemes. ECCV. 2010; (1): 776-789 

[29] L.-J. Li, H. Su, L. Fei-Fei, and E. P. Xing. Object bank: A high-level image representation for 
scene classification & semantic feature sparsification. NIPS. 2010: 1378-1386 

[30]  R.  Kwitt,  N.  Vasconcelos,  and  N.  Rasiwasia.  Scene  recognition  on  the  semantic  manifold. 
ECCV. 2012: 359-372 

[31]  A.  Shabou  and  H.  LeBorgne.  Locality-constrained  and  spatially  regularized  coding  for  scene 
categorization. CVPR. 2012  : 3618-3625 

[32]  A.  Bosch,  A.  Zisserman,  and  X.  Muoz.  Scene  classification  using  a  hybrid 
generative/discriminative approach. IEEE Trans. Pattern Anal. Mach. Intell. 2008; 30(4): 712-727. 

[33]  J.  Wu  and  J.M.  Rehg.  Centrist:  A  visual  descriptor  for  scene  categorization.   IEEE  Trans. 
Pattern Anal. Mach. Intell. 2011; 33(8): 1489-1501. 

[34]  J.  Wu  and  J.  M.  Rehg.  Beyond  the  Euclidean  distance:  Creating  effective  visual  codebooks 
using the histogram intersection kernel. ICCV. 2009: 630-637 

[35] Q. Li, J.Wu, and Z. Tu. Harvesting mid-level visual concepts from large-scale internet images. 
CVPR, 2013:    851-858. 

[36]  Y.-L.  Boureau,  F.  Bach,  Y.  LeCun,  and  J.  Ponce.  Learning  mid-level  features  for 
recognition.   CVPR. 2010: 2559-2566. 

[37]  S.  Gao,  I.  W.  Tsang,  L.-T.  Chia,  and  P.  Zhao.  Local  features  are  not  lonely–Laplacian  sparse 
coding for image classification. CVPR. 2010: 3555-3561. 

